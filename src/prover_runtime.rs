//! Prover Runtime
//!
//! Main orchestrator for authenticated and anonymous proving modes.
//! Coordinates online workers (network I/O) and offline workers (computation).

use crate::consts::prover::{EVENT_QUEUE_SIZE, RESULT_QUEUE_SIZE, TASK_QUEUE_SIZE};
use crate::environment::Environment;
use crate::events::Event;
use crate::orchestrator::OrchestratorClient;
use crate::task::Task;
use crate::task_cache::TaskCache;
use crate::workers::{offline, online};
use crate::system::{check_memory_pressure, perform_memory_cleanup};
use crate::prover::get_defragmenter;
use ed25519_dalek::SigningKey;
use nexus_sdk::stwo::seq::Proof;
use tokio::sync::{broadcast, mpsc};
use tokio::task::JoinHandle;
use std::sync::atomic::{AtomicU64, Ordering};
use std::time::Duration;
use parking_lot::Mutex;
use once_cell::sync::Lazy;
use rand;
use log::{debug, warn};
use crate::orchestrator_client_enhanced::EnhancedOrchestratorClient;
use sha3::Digest;
use postcard;
use std::sync::Arc;

/// Maximum number of completed tasks to keep in memory. Chosen to be larger than the task queue size.
const MAX_COMPLETED_TASKS: usize = 500;

// é«˜æ€§èƒ½æ—¶é—´æˆ³ç¼“å­˜ - é¿å…é‡å¤æ ¼å¼åŒ–
static LAST_TIMESTAMP_SEC: AtomicU64 = AtomicU64::new(0);
static CACHED_TIMESTAMP: Lazy<Mutex<String>> = Lazy::new(|| {
    Mutex::new(chrono::Local::now().format("%H:%M:%S").to_string())
});

/// é«˜æ€§èƒ½æ—¶é—´æˆ³ç”Ÿæˆ - ç§’çº§ç¼“å­˜é¿å…é‡å¤æ ¼å¼åŒ–
fn get_timestamp_efficient() -> String {
    let now_secs = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    let last = LAST_TIMESTAMP_SEC.load(Ordering::Relaxed);
    
    if now_secs != last && LAST_TIMESTAMP_SEC.compare_exchange_weak(
        last, now_secs, Ordering::Relaxed, Ordering::Relaxed
    ).is_ok() {
        // ä»…å½“ç§’æ•°å˜åŒ–æ—¶é‡æ–°æ ¼å¼åŒ–
        let new_timestamp = chrono::Local::now().format("%H:%M:%S").to_string();
        *CACHED_TIMESTAMP.lock() = new_timestamp.clone();
        new_timestamp
    } else {
        // ä½¿ç”¨ç¼“å­˜çš„æ—¶é—´æˆ³
        CACHED_TIMESTAMP.lock().clone()
    }
}

/// Starts authenticated workers that fetch tasks from the orchestrator and process them.
pub async fn start_authenticated_workers(
    node_id: u64,
    signing_key: SigningKey,
    orchestrator: OrchestratorClient,
    num_workers: usize,
    shutdown: broadcast::Receiver<()>,
    environment: Environment,
    client_id: String,
) -> (mpsc::Receiver<Event>, Vec<JoinHandle<()>>) {
    let mut join_handles = Vec::new();
    // Worker events
    let (event_sender, event_receiver) = mpsc::channel::<Event>(EVENT_QUEUE_SIZE);

    // A bounded list of recently fetched task IDs (prevents refetching currently processing tasks)
    let enqueued_tasks = TaskCache::new(MAX_COMPLETED_TASKS);

    // Task fetching
    let (task_sender, task_receiver) = mpsc::channel::<Task>(TASK_QUEUE_SIZE);
    let verifying_key = signing_key.verifying_key();
    let fetch_prover_tasks_handle = {
        let orchestrator = orchestrator.clone();
        let event_sender = event_sender.clone();
        let shutdown = shutdown.resubscribe(); // Clone the receiver for task fetching
        tokio::spawn(async move {
            online::fetch_prover_tasks(
                node_id,
                verifying_key,
                Box::new(orchestrator),
                task_sender,
                event_sender,
                shutdown,
                enqueued_tasks,
            )
            .await;
        })
    };
    join_handles.push(fetch_prover_tasks_handle);

    // Workers
    let (result_sender, result_receiver) = mpsc::channel::<(Task, Proof)>(RESULT_QUEUE_SIZE);

    let (worker_senders, worker_handles) = offline::start_workers(
        num_workers,
        result_sender,
        event_sender.clone(),
        shutdown.resubscribe(),
        environment,
        client_id,
    );
    join_handles.extend(worker_handles);

    // Dispatch tasks to workers
    let dispatcher_handle =
        offline::start_dispatcher(task_receiver, worker_senders, shutdown.resubscribe());
    join_handles.push(dispatcher_handle);

    // A bounded list of recently completed task IDs (prevents duplicate proof submissions)
    let successful_tasks = TaskCache::new(MAX_COMPLETED_TASKS);

    // Send proofs to the orchestrator
    let submit_proofs_handle = online::submit_proofs(
        signing_key,
        Box::new(orchestrator),
        num_workers,
        result_receiver,
        event_sender.clone(),
        shutdown.resubscribe(),
        successful_tasks.clone(),
    )
    .await;
    join_handles.push(submit_proofs_handle);

    (event_receiver, join_handles)
}

/// Starts anonymous workers that repeatedly prove a program with hardcoded inputs.
pub async fn start_anonymous_workers(
    num_workers: usize,
    shutdown: broadcast::Receiver<()>,
    environment: Environment,
    client_id: String,
) -> (mpsc::Receiver<Event>, Vec<JoinHandle<()>>) {
    offline::start_anonymous_workers(num_workers, shutdown, environment, client_id).await
}

/// å†…å­˜ä¼˜åŒ–çš„å¤šèŠ‚ç‚¹æ‰¹å¤„ç†æ¨¡å¼ - è‡ªé€‚åº”å†…å­˜ç®¡ç†
pub async fn start_optimized_batch_workers(
    nodes: Vec<u64>,
    _orchestrator: OrchestratorClient,
    num_workers_per_node: usize,
    start_delay: f64,
    proof_interval: u64,
    environment: Environment,
    shutdown: broadcast::Receiver<()>,
    status_callback: Option<Box<dyn Fn(u64, String) + Send + Sync + 'static>>,
) -> Vec<JoinHandle<()>> {
    let mut join_handles = Vec::new();
    let defragmenter = get_defragmenter();
    
    // é¢„åˆå§‹åŒ–è¯æ˜å™¨ - ç¡®ä¿å®ƒä»¬è¢«å…±äº«
    let _ = crate::prover::get_or_create_default_prover().await;
    let _ = crate::prover::get_or_create_initial_prover().await;
    
    // æŒ‰åºå¯åŠ¨å„èŠ‚ç‚¹
    for (index, node_id) in nodes.iter().enumerate() {
        // æ·»åŠ å¯åŠ¨å»¶è¿Ÿ
        if index > 0 {
            tokio::time::sleep(std::time::Duration::from_secs_f64(start_delay)).await;
        }
        
        // æ£€æŸ¥å†…å­˜å‹åŠ›ï¼Œå¦‚æœéœ€è¦åˆ™ç­‰å¾…æ›´é•¿æ—¶é—´
        if check_memory_pressure() {
            debug!("èŠ‚ç‚¹ {} å¯åŠ¨å‰æ£€æµ‹åˆ°å†…å­˜å‹åŠ›ï¼Œæ‰§è¡Œæ¸…ç†...", node_id);
            perform_memory_cleanup();
            
            // åœ¨èŠ‚ç‚¹å¯åŠ¨å‰è¿›è¡Œå†…å­˜ç¢ç‰‡æ•´ç†
            if defragmenter.should_defragment().await {
                let result = defragmenter.defragment().await;
                debug!("èŠ‚ç‚¹ {} å¯åŠ¨å‰å†…å­˜ç¢ç‰‡æ•´ç†: {:.1}% â†’ {:.1}%", 
                      node_id, result.memory_before * 100.0, result.memory_after * 100.0);
            }
            
            // é¢å¤–ç­‰å¾…è®©å†…å­˜æ¸…ç†ç”Ÿæ•ˆ
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
        
        // è·å–å¯†é’¥
        let signing_key = match crate::key_manager::load_or_generate_signing_key() {
            Ok(key) => key,
            Err(e) => {
                warn!("èŠ‚ç‚¹ {} åŠ è½½ç­¾åå¯†é’¥å¤±è´¥: {}", node_id, e);
                // ä½¿ç”¨å…‹éš†çš„å›è°ƒ
                if let Some(ref callback) = status_callback {
                    callback(*node_id, format!("åŠ è½½å¯†é’¥å¤±è´¥: {}", e));
                }
                continue;
            }
        };
        
        let node_id = *node_id;
        // ä½¿ç”¨å¢å¼ºç‰ˆå®¢æˆ·ç«¯
        let enhanced_orchestrator = EnhancedOrchestratorClient::new(environment.clone());
        let shutdown_rx = shutdown.resubscribe();
        let environment = environment.clone();
        let client_id = format!("{:x}", md5::compute(node_id.to_le_bytes()));
        
        // åˆ›å»ºä¸€ä¸ªæ–°çš„å›è°ƒé—­åŒ…ï¼Œå°†Box<dyn Fn>è½¬æ¢ä¸ºå¯ä»¥åœ¨å¤šä¸ªä»»åŠ¡é—´å…±äº«çš„Arc<dyn Fn>
        let callback_arc = match &status_callback {
            Some(cb) => {
                // åˆ›å»ºä¸€ä¸ªå¯ä»¥å…‹éš†çš„ArcåŒ…è£…å›è°ƒ
                let cb_arc = Arc::new(move |id: u64, msg: String| {
                    cb(id, msg);
                }) as Arc<dyn Fn(u64, String) + Send + Sync>;
                Some(cb_arc)
            },
            None => None,
        };
        
        let handle = tokio::spawn(async move {
            run_memory_optimized_node(
                node_id,
                signing_key,
                enhanced_orchestrator,
                num_workers_per_node,
                proof_interval,
                environment,
                client_id,
                shutdown_rx,
                callback_arc,
            ).await;
        });
        
        join_handles.push(handle);
    }
    
    join_handles
}

/// å†…å­˜ä¼˜åŒ–çš„å•èŠ‚ç‚¹è¿è¡Œå‡½æ•° - åŒ…å«429é”™è¯¯å¤„ç†å’Œé”™è¯¯æ¢å¤åŠŸèƒ½
async fn run_memory_optimized_node(
    node_id: u64,
    signing_key: SigningKey,
    orchestrator: EnhancedOrchestratorClient,
    _num_workers: usize,
    proof_interval: u64,
    environment: Environment,
    client_id: String,
    mut shutdown: broadcast::Receiver<()>,
    status_callback: Option<Arc<dyn Fn(u64, String) + Send + Sync>>,
) {
    const MAX_ATTEMPTS: usize = 5;
    let mut consecutive_failures = 0;
    let mut proof_count = 0;
    
    // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
    let update_status = |status: String| {
        if let Some(ref callback) = &status_callback {
            callback(node_id, status);
        }
    };
    
    update_status(format!("ğŸš€ å¯åŠ¨ä¸­"));
    
    loop {
        // é¦–å…ˆæ£€æŸ¥å…³é—­ä¿¡å·
        if shutdown.try_recv().is_ok() {
            update_status("å·²åœæ­¢".to_string());
            break;
        }
        
        // æ£€æŸ¥å†…å­˜å‹åŠ›
        if check_memory_pressure() {
            update_status("âš ï¸ æ£€æµ‹åˆ°å†…å­˜å‹åŠ›ï¼Œæ‰§è¡Œæ¸…ç†...".to_string());
            perform_memory_cleanup();
            tokio::time::sleep(Duration::from_millis(500)).await;
        }
        
        // è·å–å†…å­˜ç¢ç‰‡æ•´ç†å™¨çŠ¶æ€
        let defragmenter = get_defragmenter();
        if defragmenter.should_defragment().await {
            update_status("ğŸ§¹ æ‰§è¡Œå†…å­˜ç¢ç‰‡æ•´ç†...".to_string());
            let result = defragmenter.defragment().await;
            update_status(format!("å†…å­˜: {:.1}% â†’ {:.1}% (é‡Šæ”¾ {:.1}%)",
                             result.memory_before * 100.0,
                             result.memory_after * 100.0,
                             result.memory_freed_percentage()));
        }
        
        let timestamp = get_timestamp_efficient();
        let mut attempt = 1;
        let mut success = false;
        
        // å°è¯•è·å–ä»»åŠ¡å¹¶ç”Ÿæˆè¯æ˜
        while attempt <= MAX_ATTEMPTS {
            update_status(format!("[{}] è·å–ä»»åŠ¡ ({}/{})", timestamp, attempt, MAX_ATTEMPTS));
            
            let verifying_key = signing_key.verifying_key();
            match orchestrator.get_task(&node_id.to_string(), &verifying_key).await {
                Ok(task) => {
                    // ä»»åŠ¡è·å–æˆåŠŸï¼Œå¼€å§‹ç”Ÿæˆè¯æ˜
                    update_status(format!("[{}] æ­£åœ¨ç”Ÿæˆè¯æ˜...", timestamp));
                    
                    match crate::prover::authenticated_proving(&task, &environment, client_id.clone()).await {
                        Ok(proof) => {
                            // è¯æ˜ç”ŸæˆæˆåŠŸï¼Œå¼€å§‹æäº¤
                            update_status(format!("[{}] æ­£åœ¨æäº¤è¯æ˜...", timestamp));
                            
                            // è®¡ç®—å“ˆå¸Œ
                            // ä½¿ç”¨æ­£ç¡®çš„sha3::Digest traitæ–¹æ³•
                            let mut hasher = sha3::Sha3_256::new();
                            // å°†Proofè½¬æ¢ä¸ºVec<u8>
                            let proof_bytes = postcard::to_allocvec(&proof)
                                .unwrap_or_else(|_| Vec::new());
                            hasher.update(&proof_bytes);
                            let hash = hasher.finalize();
                            let proof_hash = format!("{:x}", hash);
                            
                            // æäº¤è¯æ˜ - å…‹éš†ç­¾åå¯†é’¥ä»¥é¿å…æ‰€æœ‰æƒé—®é¢˜
                            match orchestrator.submit_proof(&task.task_id, &proof_hash, proof_bytes, signing_key.clone()).await {
                                Ok(_) => {
                                    // æˆåŠŸæäº¤è¯æ˜
                                    proof_count += 1;
                                    consecutive_failures = 0;
                                    success = true;
                                    update_status(format!("[{}] âœ… è¯æ˜ #{} å®Œæˆ", timestamp, proof_count));
                                    break;
                                }
                                Err(e) => {
                                    let error_str = e.to_string();
                                    if error_str.contains("RATE_LIMITED") || error_str.contains("429") {
                                        // é€Ÿç‡é™åˆ¶é”™è¯¯ - ä½¿ç”¨éšæœºç­‰å¾…æ—¶é—´
                                        let wait_time = 40 + rand::random::<u64>() % 41; // 40-80ç§’éšæœº
                                        update_status(format!("[{}] ğŸš« é€Ÿç‡é™åˆ¶ (429) - ç­‰å¾… {}s", timestamp, wait_time));
                                        tokio::time::sleep(Duration::from_secs(wait_time)).await;
                                    } else {
                                        update_status(format!("[{}] âŒ æäº¤å¤±è´¥: {}", timestamp, error_str));
                                        tokio::time::sleep(Duration::from_secs(2)).await;
                                    }
                                    attempt += 1;
                                }
                            }
                        }
                        Err(e) => {
                            update_status(format!("[{}] âŒ è¯æ˜ç”Ÿæˆå¤±è´¥: {}", timestamp, e));
                            tokio::time::sleep(Duration::from_secs(2)).await;
                            attempt += 1;
                        }
                    }
                }
                Err(e) => {
                    let error_str = e.to_string();
                    if error_str.contains("RATE_LIMITED") || error_str.contains("429") {
                        // é€Ÿç‡é™åˆ¶é”™è¯¯ - ä½¿ç”¨éšæœºç­‰å¾…æ—¶é—´
                        let wait_time = 40 + rand::random::<u64>() % 41; // 40-80ç§’éšæœº
                        update_status(format!("[{}] ğŸš« é€Ÿç‡é™åˆ¶ (429) - ç­‰å¾… {}s", timestamp, wait_time));
                        tokio::time::sleep(Duration::from_secs(wait_time)).await;
                    } else {
                        update_status(format!("[{}] âŒ è·å–ä»»åŠ¡å¤±è´¥: {}", timestamp, error_str));
                        tokio::time::sleep(Duration::from_secs(2)).await;
                    }
                    attempt += 1;
                }
            }
            
            // æ£€æŸ¥å…³é—­ä¿¡å·
            if shutdown.try_recv().is_ok() {
                update_status("å·²åœæ­¢".to_string());
                return;
            }
        }
        
        if success {
            // å‘é€åˆ†æäº‹ä»¶
            let _ = crate::analytics::track(
                "cli_proof_node_batch_v3".to_string(),
                serde_json::json!({
                    "node_id": node_id,
                    "proof_count": proof_count,
                }),
                &environment,
                client_id.clone(),
            ).await;
            
            // ç­‰å¾…æŒ‡å®šçš„è¯æ˜é—´éš”
            tokio::time::sleep(Duration::from_secs(proof_interval)).await;
        } else {
            consecutive_failures += 1;
            update_status(format!("[{}] âš ï¸ æ‰€æœ‰å°è¯•å‡å¤±è´¥ ({}/âˆ)", timestamp, consecutive_failures));
            
            // å¤±è´¥åç­‰å¾…æ—¶é—´æ¯”æ­£å¸¸è¯æ˜é—´éš”é•¿ä¸€äº›
            tokio::time::sleep(Duration::from_secs((proof_interval + 5).min(15))).await;
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::orchestrator::MockOrchestrator;
    use crate::prover_runtime::{Event, MAX_COMPLETED_TASKS, online::fetch_prover_tasks};
    use crate::task::Task;
    use crate::task_cache::TaskCache;
    use std::time::Duration;
    use tokio::sync::{broadcast, mpsc};

    /// Creates a mock orchestrator client that simulates fetching tasks.
    fn get_mock_orchestrator_client() -> MockOrchestrator {
        let mut i = 0;
        let mut mock = MockOrchestrator::new();
        mock.expect_get_proof_task().returning_st(move |_, _| {
            // Simulate a task with dummy data
            let task = Task::new(i.to_string(), format!("Task {}", i), vec![1, 2, 3]);
            i += 1;
            Ok(task)
        });
        mock
    }

    #[tokio::test]
    // Should fetch and enqueue tasks from the orchestrator.
    async fn test_task_fetching() {
        let orchestrator_client = Box::new(get_mock_orchestrator_client());
        let signer_key = ed25519_dalek::SigningKey::generate(&mut rand::rngs::OsRng);
        let verifying_key = signer_key.verifying_key();
        let node_id = 1234;

        let task_queue_size = 10;
        let (task_sender, mut task_receiver) = mpsc::channel::<Task>(task_queue_size);

        // Run task_master in a tokio task to stay in the same thread context
        let (shutdown_sender, _) = broadcast::channel(1); // Only one shutdown signal needed
        let (event_sender, _event_receiver) = mpsc::channel::<Event>(100);
        let shutdown_receiver = shutdown_sender.subscribe();
        let successful_tasks = TaskCache::new(MAX_COMPLETED_TASKS);

        let task_master_handle = tokio::spawn(async move {
            fetch_prover_tasks(
                node_id,
                verifying_key,
                orchestrator_client,
                task_sender,
                event_sender,
                shutdown_receiver,
                successful_tasks,
            )
            .await;
        });

        // Receive tasks
        let mut received = 0;
        for _i in 0..task_queue_size {
            match tokio::time::timeout(Duration::from_secs(2), task_receiver.recv()).await {
                Ok(Some(task)) => {
                    println!("Received task {}: {:?}", received, task);
                    received += 1;
                }
                Ok(None) => {
                    eprintln!("Channel closed unexpectedly");
                    break;
                }
                Err(_) => {
                    eprintln!("Timed out waiting for task {}", received);
                    break;
                }
            }
        }

        task_master_handle.abort();
    }
}
