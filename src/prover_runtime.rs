//! Prover Runtime
//!
//! Main orchestrator for authenticated and anonymous proving modes.
//! Coordinates online workers (network I/O) and offline workers (computation).

use crate::consts::prover::{EVENT_QUEUE_SIZE, RESULT_QUEUE_SIZE, TASK_QUEUE_SIZE};
use crate::environment::Environment;
use crate::events::Event;
use crate::orchestrator::OrchestratorClient;
use crate::task::Task;
use crate::task_cache::TaskCache;
use crate::workers::{offline, online};
use crate::system::{check_memory_pressure, perform_memory_cleanup};
use crate::prover::get_defragmenter;
use ed25519_dalek::SigningKey;
use nexus_sdk::stwo::seq::Proof;
use tokio::sync::{broadcast, mpsc};
use tokio::task::JoinHandle;
use std::sync::atomic::{AtomicU64, Ordering, AtomicBool, AtomicU32};
use std::time::Duration;
use parking_lot::Mutex;
use once_cell::sync::Lazy;
use rand;
use log::{debug, warn};
use crate::orchestrator_client_enhanced::EnhancedOrchestratorClient;
use sha3::Digest;
use postcard;
use std::sync::Arc;
use std::collections::HashMap;
use std::time::Instant;
use std::future::Future;
use std::collections::HashSet;

/// Maximum number of completed tasks to keep in memory. Chosen to be larger than the task queue size.
const MAX_COMPLETED_TASKS: usize = 500;

// æ·»åŠ å…¨å±€è°ƒè¯•è¾“å‡ºæ§åˆ¶
// è®¾ç½®ä¸ºtrueæ—¶æ˜¾ç¤ºæ›´å¤šè°ƒè¯•ä¿¡æ¯ï¼Œfalseæ—¶åªæ˜¾ç¤ºå¿…è¦ä¿¡æ¯
const VERBOSE_OUTPUT: bool = false;

// é«˜æ€§èƒ½æ—¶é—´æˆ³ç¼“å­˜ - é¿å…é‡å¤æ ¼å¼åŒ–
static LAST_TIMESTAMP_SEC: AtomicU64 = AtomicU64::new(0);
static CACHED_TIMESTAMP: Lazy<Mutex<String>> = Lazy::new(|| {
    Mutex::new(chrono::Local::now().format("%H:%M:%S").to_string())
});

/// é«˜æ€§èƒ½æ—¶é—´æˆ³ç”Ÿæˆ - ç§’çº§ç¼“å­˜é¿å…é‡å¤æ ¼å¼åŒ–
fn get_timestamp_efficient() -> String {
    let now_secs = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs();
    
    let last = LAST_TIMESTAMP_SEC.load(Ordering::Relaxed);
    
    if now_secs != last && LAST_TIMESTAMP_SEC.compare_exchange_weak(
        last, now_secs, Ordering::Relaxed, Ordering::Relaxed
    ).is_ok() {
        // ä»…å½“ç§’æ•°å˜åŒ–æ—¶é‡æ–°æ ¼å¼åŒ–
        let new_timestamp = chrono::Local::now().format("%H:%M:%S").to_string();
        *CACHED_TIMESTAMP.lock() = new_timestamp.clone();
        new_timestamp
    } else {
        // ä½¿ç”¨ç¼“å­˜çš„æ—¶é—´æˆ³
        CACHED_TIMESTAMP.lock().clone()
    }
}

/// å…¨å±€è¯·æ±‚é™æµå™¨ - é™åˆ¶å¯¹æœåŠ¡å™¨çš„è¯·æ±‚é¢‘ç‡
/// 
/// åŠ¨æ€è°ƒæ•´æœºåˆ¶:
/// - åˆå§‹é€Ÿç‡: æ¯ç§’1ä¸ªè¯·æ±‚
/// - å¦‚æœæ£€æµ‹åˆ°429é”™è¯¯: é™ä½10%é€Ÿç‡ (ä¾‹å¦‚: 1.0 -> 0.9 -> 0.81 ...)
/// - å¦‚æœè¯·æ±‚æˆåŠŸ: å¢åŠ 10%é€Ÿç‡ (ä¾‹å¦‚: 1.0 -> 1.1 -> 1.21 ...)
/// - é€Ÿç‡é™åˆ¶èŒƒå›´: æœ€ä½æ¯10ç§’1ä¸ªè¯·æ±‚ (0.1/ç§’), æœ€é«˜æ¯ç§’5ä¸ªè¯·æ±‚ (5.0/ç§’)
pub struct GlobalRateLimiter {
    last_request_time: Instant,
    request_interval: Duration,
    requests_per_second: f64,
    total_requests: u64,
}

impl GlobalRateLimiter {
    pub fn new(requests_per_second: f64) -> Self {
        let interval = Duration::from_secs_f64(1.0 / requests_per_second);
        if VERBOSE_OUTPUT {
            println!("ğŸš¦ åˆå§‹åŒ–å…¨å±€è¯·æ±‚é™æµå™¨ - æ¯ç§’ {} ä¸ªè¯·æ±‚ï¼Œé—´éš” {:.2}ms", 
                    requests_per_second, interval.as_millis());
        }
        
        Self {
            last_request_time: Instant::now() - interval, // åˆå§‹åŒ–ä¸ºå¯ä»¥ç«‹å³å‘é€è¯·æ±‚
            request_interval: interval,
            requests_per_second,
            total_requests: 0,
        }
    }
    
    /// è°ƒæ•´è¯·æ±‚é€Ÿç‡
    pub fn set_rate(&mut self, requests_per_second: f64) {
        self.requests_per_second = requests_per_second;
        self.request_interval = Duration::from_secs_f64(1.0 / requests_per_second);
        if VERBOSE_OUTPUT {
            println!("ğŸš¦ è°ƒæ•´å…¨å±€è¯·æ±‚é™æµå™¨ - æ¯ç§’ {} ä¸ªè¯·æ±‚ï¼Œé—´éš” {:.2}ms", 
                    requests_per_second, self.request_interval.as_millis());
        }
    }
    
    /// è·å–å½“å‰è¯·æ±‚é€Ÿç‡
    pub fn get_rate(&self) -> f64 {
        self.requests_per_second
    }
    
    /// è·å–æ€»è¯·æ±‚æ•°
    pub fn get_total_requests(&self) -> u64 {
        self.total_requests
    }
}

// åˆ›å»ºå…¨å±€é™æµå™¨å®ä¾‹ - æ¯ç§’1ä¸ªè¯·æ±‚
static GLOBAL_RATE_LIMITER: Lazy<Mutex<GlobalRateLimiter>> = Lazy::new(|| {
    Mutex::new(GlobalRateLimiter::new(1.0))
});

// å…¨å±€429é”™è¯¯è®¡æ•°å™¨
static RECENT_429_ERRORS: Lazy<AtomicU32> = Lazy::new(|| AtomicU32::new(0));

/// å¢åŠ 429é”™è¯¯è®¡æ•°
pub fn increment_429_error_count() {
    RECENT_429_ERRORS.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
}

/// è·å–429é”™è¯¯è®¡æ•°ï¼ˆä¸é‡ç½®ï¼‰
pub fn get_429_error_count() -> u32 {
    RECENT_429_ERRORS.load(std::sync::atomic::Ordering::SeqCst)
}

/// è·å–å¹¶é‡ç½®429é”™è¯¯è®¡æ•°
#[allow(dead_code)]
pub fn get_and_reset_429_error_count() -> u32 {
    RECENT_429_ERRORS.swap(0, std::sync::atomic::Ordering::SeqCst)
}

/// é‡ç½®429é”™è¯¯è®¡æ•°
pub fn reset_429_error_count() {
    RECENT_429_ERRORS.store(0, std::sync::atomic::Ordering::SeqCst);
}

/// å…¨å±€APIè¯·æ±‚å‡½æ•° - æ‰€æœ‰å¯¹æœåŠ¡å™¨çš„è¯·æ±‚éƒ½åº”è¯¥é€šè¿‡è¿™ä¸ªå‡½æ•°
pub async fn make_api_request<F, T>(request_func: F) -> T 
where 
    F: Future<Output = T>,
{
    // ç­‰å¾…é™æµå™¨å…è®¸å‘é€è¯·æ±‚
    {
        // åœ¨å•ç‹¬çš„ä½œç”¨åŸŸä¸­è·å–é”å¹¶ç­‰å¾…
        let wait_duration = {
            let mut limiter = GLOBAL_RATE_LIMITER.lock();
            let now = Instant::now();
            let elapsed = now.duration_since(limiter.last_request_time);
            
            // è®¡ç®—éœ€è¦ç­‰å¾…çš„æ—¶é—´
            let wait_time = if elapsed < limiter.request_interval {
                limiter.request_interval - elapsed
            } else {
                Duration::from_secs(0)
            };
            
            // æ›´æ–°ä¸Šæ¬¡è¯·æ±‚æ—¶é—´å’Œæ€»è¯·æ±‚æ•°
            limiter.last_request_time = now;
            limiter.total_requests += 1;
            
            // æ¯10ä¸ªè¯·æ±‚è¾“å‡ºä¸€æ¬¡æ—¥å¿—ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
            if limiter.total_requests % 10 == 0 && VERBOSE_OUTPUT {
                println!("ğŸš¦ å…¨å±€é™æµ: ç­‰å¾… {:.2}ms åå‘é€ä¸‹ä¸€ä¸ªè¯·æ±‚ (æ€»è¯·æ±‚æ•°: {})", 
                        wait_time.as_millis(), limiter.total_requests);
            }
            
            wait_time
        }; // é”åœ¨è¿™é‡Œé‡Šæ”¾
        
        // é”é‡Šæ”¾åå†ç­‰å¾…
        if wait_duration.as_nanos() > 0 {
            tokio::time::sleep(wait_duration).await;
        }
    }
    
    // å‘é€è¯·æ±‚
    request_func.await
}

/// è°ƒæ•´å…¨å±€è¯·æ±‚é€Ÿç‡
pub fn set_global_request_rate(requests_per_second: f64) {
    let mut limiter = GLOBAL_RATE_LIMITER.lock();
    limiter.set_rate(requests_per_second);
}

/// è·å–å…¨å±€è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
pub fn get_global_request_stats() -> (f64, u64) {
    let limiter = GLOBAL_RATE_LIMITER.lock();
    (limiter.get_rate(), limiter.get_total_requests())
}

/// å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡é™åˆ¶å™¨
pub static GLOBAL_ACTIVE_NODES: Lazy<Mutex<HashSet<u64>>> = Lazy::new(|| Mutex::new(HashSet::new()));

/// è·å–å½“å‰å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡
pub fn get_global_active_node_count() -> usize {
    let nodes = GLOBAL_ACTIVE_NODES.lock();
    nodes.len()
}

/// æ·»åŠ èŠ‚ç‚¹åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
pub fn add_global_active_node(node_id: u64) -> bool {
    let mut nodes = GLOBAL_ACTIVE_NODES.lock();
    nodes.insert(node_id)
}

/// ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆç§»é™¤èŠ‚ç‚¹
pub fn remove_global_active_node(node_id: u64) -> bool {
    let mut nodes = GLOBAL_ACTIVE_NODES.lock();
    nodes.remove(&node_id)
}

/// æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨å…¨å±€æ´»è·ƒé›†åˆä¸­
pub fn is_node_globally_active(node_id: u64) -> bool {
    let nodes = GLOBAL_ACTIVE_NODES.lock();
    nodes.contains(&node_id)
}

/// æ¸…ç†å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆï¼Œç¡®ä¿åªä¿ç•™çœŸæ­£æ´»è·ƒçš„èŠ‚ç‚¹
pub fn sync_global_active_nodes(active_threads: &Arc<Mutex<HashMap<u64, bool>>>, max_concurrent: usize) {
    let mut nodes = GLOBAL_ACTIVE_NODES.lock();
    
    // è·å–å½“å‰çœŸæ­£æ´»è·ƒçš„èŠ‚ç‚¹
    let active_nodes: HashSet<u64> = {
        let threads_guard = active_threads.lock();
        threads_guard.iter()
            .filter(|pair| *pair.1)
            .map(|(&id, _)| id)
            .collect()
    };
    
    // å¦‚æœæ´»è·ƒèŠ‚ç‚¹ä¸ºç©ºä½†å…¨å±€èŠ‚ç‚¹ä¸ä¸ºç©ºï¼Œä¿ç•™å…¨å±€èŠ‚ç‚¹
    if active_nodes.is_empty() && !nodes.is_empty() {
        println!("âš ï¸ åŒæ­¥è­¦å‘Š: æœ¬åœ°æ´»è·ƒèŠ‚ç‚¹ä¸ºç©ºï¼Œä½†å…¨å±€æœ‰ {} ä¸ªæ´»è·ƒèŠ‚ç‚¹ï¼Œä¿ç•™å…¨å±€çŠ¶æ€", nodes.len());
        return;
    }
    
    // æ¸…ç©ºå¹¶é‡å»ºå…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
    nodes.clear();
    
    // ä»…æ·»åŠ æœ€å¤šmax_concurrentä¸ªæ´»è·ƒèŠ‚ç‚¹
    for node_id in active_nodes.iter().take(max_concurrent) {
        nodes.insert(*node_id);
    }
    
    if VERBOSE_OUTPUT {
        println!("ğŸŒ å…¨å±€æ´»è·ƒèŠ‚ç‚¹åŒæ­¥ - å½“å‰æ´»è·ƒèŠ‚ç‚¹æ•°é‡: {}/{}", nodes.len(), max_concurrent);
    }
}

/// Starts authenticated workers that fetch tasks from the orchestrator and process them.
pub async fn start_authenticated_workers(
    node_id: u64,
    signing_key: SigningKey,
    orchestrator: OrchestratorClient,
    num_workers: usize,
    shutdown: broadcast::Receiver<()>,
    environment: Environment,
    client_id: String,
) -> (mpsc::Receiver<Event>, Vec<JoinHandle<()>>) {
    let mut join_handles = Vec::new();
    // Worker events
    let (event_sender, event_receiver) = mpsc::channel::<Event>(EVENT_QUEUE_SIZE);

    // A bounded list of recently fetched task IDs (prevents refetching currently processing tasks)
    let enqueued_tasks = TaskCache::new(MAX_COMPLETED_TASKS);
    
    // åˆ›å»ºèŠ‚ç‚¹é€Ÿç‡é™åˆ¶è·Ÿè¸ªå™¨
    let rate_limit_tracker = online::NodeRateLimitTracker::new();

    // Task fetching
    let (task_sender, task_receiver) = mpsc::channel::<Task>(TASK_QUEUE_SIZE);
    let verifying_key = signing_key.verifying_key();
    let fetch_prover_tasks_handle = {
        let orchestrator = orchestrator.clone();
        let event_sender = event_sender.clone();
        let shutdown = shutdown.resubscribe(); // Clone the receiver for task fetching
        let rate_limit_tracker_clone = rate_limit_tracker.clone();
        tokio::spawn(async move {
            online::fetch_prover_tasks(
                node_id,
                verifying_key,
                Box::new(orchestrator),
                task_sender,
                event_sender,
                shutdown,
                enqueued_tasks,
                rate_limit_tracker_clone,
            )
            .await;
        })
    };
    join_handles.push(fetch_prover_tasks_handle);

    // Workers
    let (result_sender, result_receiver) = mpsc::channel::<(Task, Proof)>(RESULT_QUEUE_SIZE);

    let (worker_senders, worker_handles) = offline::start_workers(
        num_workers,
        result_sender,
        event_sender.clone(),
        shutdown.resubscribe(),
        environment,
        client_id,
    );
    join_handles.extend(worker_handles);

    // Dispatch tasks to workers
    let dispatcher_handle =
        offline::start_dispatcher(task_receiver, worker_senders, shutdown.resubscribe());
    join_handles.push(dispatcher_handle);

    // A bounded list of recently completed task IDs (prevents duplicate proof submissions)
    let successful_tasks = TaskCache::new(MAX_COMPLETED_TASKS);

    // Send proofs to the orchestrator
    let submit_proofs_handle = online::submit_proofs(
        signing_key,
        Box::new(orchestrator),
        num_workers,
        result_receiver,
        event_sender.clone(),
        shutdown.resubscribe(),
        successful_tasks.clone(),
        rate_limit_tracker,
    )
    .await;
    join_handles.push(submit_proofs_handle);

    (event_receiver, join_handles)
}

/// Starts anonymous workers that repeatedly prove a program with hardcoded inputs.
pub async fn start_anonymous_workers(
    num_workers: usize,
    shutdown: broadcast::Receiver<()>,
    environment: Environment,
    client_id: String,
) -> (mpsc::Receiver<Event>, Vec<JoinHandle<()>>) {
    offline::start_anonymous_workers(num_workers, shutdown, environment, client_id).await
}

/// å†…å­˜ä¼˜åŒ–çš„å¤šèŠ‚ç‚¹æ‰¹å¤„ç†æ¨¡å¼ - è‡ªé€‚åº”å†…å­˜ç®¡ç†
pub async fn start_optimized_batch_workers(
    nodes: Vec<u64>,
    _orchestrator: OrchestratorClient,
    num_workers_per_node: usize,
    _start_delay: f64,
    proof_interval: u64,
    environment: Environment,
    shutdown: broadcast::Receiver<()>,
    status_callback: Option<Box<dyn Fn(u64, String) + Send + Sync + 'static>>,
    proxy_file: Option<String>,
    rotation: bool,
    max_concurrent: usize, // æ·»åŠ max_concurrentå‚æ•°
) -> (mpsc::Receiver<Event>, Vec<JoinHandle<()>>) {
    // Workeräº‹ä»¶
    let (event_sender, event_receiver) = mpsc::channel::<Event>(EVENT_QUEUE_SIZE);
    let mut join_handles = Vec::new();
    let defragmenter = get_defragmenter();
    
    // å°†å›è°ƒå‡½æ•°åŒ…è£…åœ¨Arcä¸­ï¼Œè¿™æ ·å¯ä»¥åœ¨å¤šä¸ªä»»åŠ¡ä¹‹é—´å…±äº«
    let status_callback_arc = status_callback.map(Arc::new);
    
    // é¢„åˆå§‹åŒ–è¯æ˜å™¨ - ç¡®ä¿å®ƒä»¬è¢«å…±äº«
    let _ = crate::prover::get_or_create_default_prover().await;
    let _ = crate::prover::get_or_create_initial_prover().await;
    
    // å¢åŠ åˆå§‹å»¶è¿Ÿï¼Œé¿å…ä¸€æ¬¡æ€§å¯åŠ¨å¤ªå¤šèŠ‚ç‚¹å¯¼è‡´429é”™è¯¯
    let initial_delay = 3.0; // 3ç§’åˆå§‹å»¶è¿Ÿ
    println!("ç­‰å¾…åˆå§‹å»¶è¿Ÿ {:.1}ç§’...", initial_delay);
    tokio::time::sleep(std::time::Duration::from_secs_f64(initial_delay)).await;
    
    // è®¡ç®—å®é™…å¹¶å‘æ•°ï¼ˆæœ€å¤§å¹¶å‘æ•°ä¸èŠ‚ç‚¹æ•°é‡çš„è¾ƒå°å€¼ï¼‰
    let actual_concurrent = max_concurrent.min(nodes.len());
    if VERBOSE_OUTPUT {
        println!("ğŸ§® è®¾ç½®çš„å¹¶å‘æ•°: {}, å®é™…å¹¶å‘æ•°: {}", max_concurrent, actual_concurrent);
    }
    
    // åˆ›å»ºä¸€ä¸ªè·Ÿè¸ªæ´»è·ƒçº¿ç¨‹çš„æ˜ å°„
    let active_threads = Arc::new(Mutex::new(HashMap::<u64, bool>::new()));
    
    // åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹ä¸ºæœªå¯åŠ¨çŠ¶æ€
    {
        let mut active_threads_guard = active_threads.lock();
        for &node_id in &nodes {
            active_threads_guard.insert(node_id, false);
        }
    }
    
    // åˆ›å»ºä¸€ä¸ªç”¨äºèŠ‚ç‚¹ç®¡ç†å™¨å’Œå·¥ä½œçº¿ç¨‹ä¹‹é—´é€šä¿¡çš„é€šé“
    let (node_tx, _node_rx) = mpsc::channel::<NodeManagerCommand>(100);
    
    // ä¿å­˜å‘é€ç«¯ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
    let _node_tx_for_workers = node_tx.clone();
    
    // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ï¼Œåˆ›å»ºèŠ‚ç‚¹é˜Ÿåˆ—å’Œæ´»åŠ¨èŠ‚ç‚¹è·Ÿè¸ªå™¨
    let all_nodes = Arc::new(nodes.clone());
    let rotation_data = if rotation {
        if VERBOSE_OUTPUT {
            println!("ğŸ”„ å¯ç”¨èŠ‚ç‚¹è½®è½¬åŠŸèƒ½ - æ€»èŠ‚ç‚¹æ•°: {}", nodes.len());
        }
        // åˆ›å»ºä¸€ä¸ªå…±äº«çš„æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—å’Œä¸‹ä¸€ä¸ªå¯ç”¨èŠ‚ç‚¹ç´¢å¼•
        let active_nodes = Arc::new(Mutex::new(Vec::new()));
        
        // åˆ›å»ºä¸€ä¸ªæ ‡å¿—ï¼Œè¡¨ç¤ºæ‰€æœ‰åˆå§‹èŠ‚ç‚¹æ˜¯å¦å·²å¯åŠ¨
        let all_nodes_started = Arc::new(std::sync::atomic::AtomicBool::new(false));
        
        // åˆ›å»ºä¸€ä¸ªèŠ‚ç‚¹æ˜ å°„è¡¨ï¼Œç”¨äºè®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„åŸå§‹ç´¢å¼•
        let node_indices = Arc::new(Mutex::new(HashMap::<u64, usize>::new()));
        
        // åˆå§‹åŒ–ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ç´¢å¼•ä¸ºå®é™…å¹¶å‘æ•°ï¼Œè¿™æ ·ç¬¬ä¸€ä¸ªè½®è½¬çš„èŠ‚ç‚¹ä¼šä»å¹¶å‘æ•°ä¹‹åå¼€å§‹
        let next_node_index = Arc::new(AtomicU64::new(actual_concurrent as u64));
        
        // åˆå§‹åŒ–æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—å’ŒèŠ‚ç‚¹ç´¢å¼•æ˜ å°„
        {
            let mut active_nodes_guard = active_nodes.lock();
            let mut node_indices_guard = node_indices.lock();
            
            // ç¡®ä¿ä½¿ç”¨å‰actual_concurrentä¸ªèŠ‚ç‚¹ï¼ˆæŒ‰ç…§ç´¢å¼•é¡ºåºï¼‰
            let mut sorted_nodes: Vec<(usize, u64)> = nodes.iter().enumerate().map(|(idx, &id)| (idx, id)).collect();
            sorted_nodes.sort_by_key(|(idx, _)| *idx);
            
            println!("ğŸ”„ åˆå§‹åŒ–æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ— - æœ€å¤§å¹¶å‘æ•°: {}, æ€»èŠ‚ç‚¹æ•°: {}", actual_concurrent, nodes.len());
            
            // åªæ·»åŠ å‰actual_concurrentä¸ªèŠ‚ç‚¹åˆ°æ´»åŠ¨é˜Ÿåˆ—
            for (idx, node_id) in sorted_nodes.iter().take(actual_concurrent) {
                // ç¡®ä¿ä¸ä¼šæ·»åŠ è¶…è¿‡æœ€å¤§å¹¶å‘æ•°çš„èŠ‚ç‚¹
                if active_nodes_guard.len() >= actual_concurrent {
                    println!("âš ï¸ æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•° {}, ä¸å†æ·»åŠ èŠ‚ç‚¹", actual_concurrent);
                    break;
                }
                
                // ç¡®ä¿èŠ‚ç‚¹ä¸é‡å¤æ·»åŠ 
                if !active_nodes_guard.contains(node_id) {
                    active_nodes_guard.push(*node_id);
                    if VERBOSE_OUTPUT {
                        println!("ğŸ”„ æ·»åŠ èŠ‚ç‚¹-{} åˆ°æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ— (ç´¢å¼•: {})", node_id, idx);
                    }
                } else {
                    println!("âš ï¸ èŠ‚ç‚¹-{} å·²åœ¨æ´»åŠ¨é˜Ÿåˆ—ä¸­ï¼Œè·³è¿‡ (ç´¢å¼•: {})", node_id, idx);
                }
                
                // æ›´æ–°èŠ‚ç‚¹ç´¢å¼•æ˜ å°„
                node_indices_guard.insert(*node_id, *idx);
                
                // æ ‡è®°èŠ‚ç‚¹ä¸ºæœªå¯åŠ¨
                let mut active_threads_guard = active_threads.lock();
                active_threads_guard.insert(*node_id, false);
            }
            
            // åˆå§‹åŒ–å‰©ä½™èŠ‚ç‚¹çš„ç´¢å¼•æ˜ å°„
            for (idx, node_id) in sorted_nodes.iter().skip(actual_concurrent) {
                node_indices_guard.insert(*node_id, *idx);
                
                // ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹éƒ½åœ¨active_threadsä¸­åˆå§‹åŒ–
                let mut active_threads_guard = active_threads.lock();
                if !active_threads_guard.contains_key(node_id) {
                    active_threads_guard.insert(*node_id, false);
                }
            }
            
            if VERBOSE_OUTPUT {
                println!("ğŸ”„ åˆå§‹æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—: {:?} (å¤§å°: {})", *active_nodes_guard, active_nodes_guard.len());
                println!("ğŸ”„ ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ç´¢å¼•: {}", next_node_index.load(std::sync::atomic::Ordering::SeqCst));
                println!("ğŸ”„ æœ€å¤§å¹¶å‘æ•°: {}, æ€»èŠ‚ç‚¹æ•°: {}", actual_concurrent, nodes.len());
            }
            
            // æœ€åå†æ¬¡ç¡®è®¤æ´»åŠ¨èŠ‚ç‚¹æ•°é‡ä¸è¶…è¿‡æœ€å¤§å¹¶å‘æ•°
            if active_nodes_guard.len() > actual_concurrent {
                println!("âš ï¸ æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—è¶…å‡ºæœ€å¤§å¹¶å‘æ•° ({} > {}), è¿›è¡Œæˆªæ–­", 
                        active_nodes_guard.len(), actual_concurrent);
                active_nodes_guard.truncate(actual_concurrent);
                println!("âœ… æ´»åŠ¨èŠ‚ç‚¹é˜Ÿåˆ—å·²æˆªæ–­è‡³ {} ä¸ªèŠ‚ç‚¹", active_nodes_guard.len());
            }
        } // é”åœ¨è¿™é‡Œé‡Šæ”¾
        
        Some((active_nodes.clone(), next_node_index.clone(), all_nodes.clone(), all_nodes_started.clone(), node_indices.clone(), actual_concurrent))
    } else {
        println!("âš ï¸ èŠ‚ç‚¹è½®è½¬åŠŸèƒ½æœªå¯ç”¨");
        None
    };
    
    // å¯åŠ¨èŠ‚ç‚¹ç®¡ç†å™¨
    if rotation {
        if let Some((active_nodes_clone, _next_node_index_clone, _all_nodes_clone, all_nodes_started_clone, _node_indices_clone, _actual_concurrent)) = rotation_data.clone() {
            let active_threads_for_manager = active_threads.clone();
            let environment_for_manager = environment.clone();
            let proxy_file_for_manager = proxy_file.clone();
            let status_callback_for_manager = status_callback_arc.clone();
            let event_sender_for_manager = event_sender.clone();
            let shutdown_for_manager = shutdown.resubscribe();
            let rotation_data_for_manager = rotation_data.clone();
            
            // æ‰“å°åˆå§‹æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨
            {
                let active_nodes_guard = active_nodes_clone.lock();
                if VERBOSE_OUTPUT {
                    println!("ğŸ”„ å¯åŠ¨èŠ‚ç‚¹ç®¡ç†å™¨çº¿ç¨‹ - åˆå§‹æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨: {:?}", *active_nodes_guard);
                }
            }
            
            if VERBOSE_OUTPUT {
                println!("ğŸ”„ å¯åŠ¨èŠ‚ç‚¹ç®¡ç†å™¨çº¿ç¨‹");
            }
            
            // åˆ›å»ºä¸€ä¸ªæ–°çš„é€šé“ï¼Œç”¨äºèŠ‚ç‚¹ç®¡ç†å™¨
            let (node_tx, node_rx) = mpsc::channel::<NodeManagerCommand>(100);
            
            // ä¿å­˜å‘é€ç«¯ï¼Œä¾›å…¶ä»–åœ°æ–¹ä½¿ç”¨
            let node_tx_for_workers = node_tx.clone();
            
            // ä½¿ç”¨node_tx_for_workersæ¥å¯åŠ¨èŠ‚ç‚¹
            {
                // è·å–æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨
                let active_nodes_guard = active_nodes_clone.lock();
                
                for node_id in active_nodes_guard.iter().copied().take(actual_concurrent) {
                    println!("ğŸš€ èŠ‚ç‚¹ç®¡ç†å™¨: åˆå§‹å¯åŠ¨èŠ‚ç‚¹-{}", node_id);
                    
                    let handle = start_node_worker(
                        node_id,
                        environment.clone(),
                        proxy_file.clone(),
                        num_workers_per_node,
                        proof_interval,
                        status_callback_arc.clone(),
                        event_sender.clone(),
                        shutdown.resubscribe(),
                        rotation_data.clone(),
                        active_threads.clone(),
                        node_tx_for_workers.clone(),
                    ).await;
                    
                    // ä¸éœ€è¦å­˜å‚¨å¥æŸ„ï¼Œå› ä¸ºå®ƒä»¬ä¼šåœ¨å®Œæˆæ—¶è‡ªåŠ¨æ¸…ç†
                    tokio::spawn(async move {
                        let _ = handle.await;
                    });
                }
            }
            
            let manager_handle = tokio::spawn(async move {
                node_manager(
                    active_nodes_clone,
                    active_threads_for_manager,
                    environment_for_manager,
                    proxy_file_for_manager,
                    num_workers_per_node,
                    proof_interval,
                    status_callback_for_manager,
                    event_sender_for_manager,
                    shutdown_for_manager,
                    node_rx,
                    rotation_data_for_manager,
                ).await;
            });
            
            join_handles.push(manager_handle);
            
            // å¯åŠ¨ä¸€ä¸ªå®šæœŸä»»åŠ¡ï¼Œç”¨äºç›‘æ§å’Œè°ƒæ•´è¯·æ±‚é€Ÿç‡
            let mut shutdown_monitor = shutdown.resubscribe();
            let monitor_handle = tokio::spawn(async move {
                let mut _consecutive_429s = 0;
                let mut consecutive_successes = 0;
                let check_interval = std::time::Duration::from_secs(30); // æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
                // åˆå§‹é€Ÿç‡ä¸ºæ¯ç§’1ä¸ªè¯·æ±‚
                let mut current_rate = 1.0;
                
                loop {
                    tokio::select! {
                        _ = shutdown_monitor.recv() => {
                            println!("ğŸ›‘ è¯·æ±‚é€Ÿç‡ç›‘æ§ä»»åŠ¡æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œæ­£åœ¨é€€å‡º");
                            break;
                        }
                        _ = tokio::time::sleep(check_interval) => {
                            // è·å–å½“å‰è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
                            let (rate, total_requests) = get_global_request_stats();
                            
                            // æ£€æŸ¥æœ€è¿‘æ˜¯å¦æœ‰429é”™è¯¯ï¼ˆä¸é‡ç½®è®¡æ•°å™¨ï¼‰
                            let recent_429s = get_429_error_count();
                            
                            if recent_429s > 0 {
                                // å¦‚æœæœ‰429é”™è¯¯ï¼Œå‡æ…¢è¯·æ±‚é€Ÿç‡ (é™ä½10%)
                                _consecutive_429s += 1;
                                consecutive_successes = 0;
                                
                                // æ¯æ¬¡å‡å°‘10%çš„é€Ÿç‡
                                current_rate = f64::max(current_rate * 0.9, 0.1); // æœ€ä½æ¯10ç§’1ä¸ªè¯·æ±‚
                                set_global_request_rate(current_rate);
                                if VERBOSE_OUTPUT {
                                    println!("âš ï¸ æ£€æµ‹åˆ°429é”™è¯¯ ({}ä¸ª)ï¼Œé™ä½è¯·æ±‚é€Ÿç‡è‡³æ¯ç§’{}ä¸ª (é™ä½10%)", 
                                            recent_429s, current_rate);
                                }
                                
                                // é‡ç½®429é”™è¯¯è®¡æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
                                reset_429_error_count();
                            } else {
                                // å¦‚æœæ²¡æœ‰429é”™è¯¯ï¼Œå¯ä»¥è€ƒè™‘é€æ¸å¢åŠ è¯·æ±‚é€Ÿç‡
                                _consecutive_429s = 0;
                                consecutive_successes += 1;
                                
                                // æ¯æ¬¡æ£€æŸ¥éƒ½å¢åŠ 10%çš„é€Ÿç‡
                                current_rate = f64::min(current_rate * 1.1, 5.0); // æœ€é«˜æ¯ç§’5ä¸ªè¯·æ±‚
                                set_global_request_rate(current_rate);
                                if VERBOSE_OUTPUT {
                                    println!("âœ… æ— 429é”™è¯¯ï¼Œå¢åŠ è¯·æ±‚é€Ÿç‡è‡³æ¯ç§’{}ä¸ª (å¢åŠ 10%)", current_rate);
                                }
                                
                                // é‡ç½®æˆåŠŸè®¡æ•°ï¼Œé¿å…è¿‡å¤§
                                if consecutive_successes >= 10 {
                                    consecutive_successes = 1;
                                }
                            }
                            
                            // è¾“å‡ºå½“å‰è¯·æ±‚ç»Ÿè®¡ä¿¡æ¯
                            if VERBOSE_OUTPUT {
                                println!("ğŸ“Š è¯·æ±‚é€Ÿç‡ç›‘æ§: å½“å‰é€Ÿç‡ = æ¯ç§’{}ä¸ªè¯·æ±‚, æ€»è¯·æ±‚æ•° = {}", rate, total_requests);
                            }
                        }
                    }
                }
            });
            
            join_handles.push(monitor_handle);
            
            // åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥ç›‘æ§æ‰€æœ‰åˆå§‹èŠ‚ç‚¹æ˜¯å¦å·²å¯åŠ¨
            let active_threads_monitor = active_threads.clone();
            let all_nodes_started_monitor = all_nodes_started_clone.clone();
            
            tokio::spawn(async move {
                // å…ˆç­‰å¾…æ›´é•¿çš„æ—¶é—´ï¼Œç¡®ä¿èŠ‚ç‚¹æœ‰è¶³å¤Ÿæ—¶é—´å¯åŠ¨
                tokio::time::sleep(std::time::Duration::from_secs(10)).await;
                
                // å¦‚æœæ²¡æœ‰ç«‹å³æ£€æµ‹åˆ°æ´»åŠ¨èŠ‚ç‚¹ï¼Œè¿›å…¥å¾ªç¯ç›‘æ§æ¨¡å¼
                let mut attempts = 0;
                let max_attempts = 30; // å¢åŠ åˆ°30æ¬¡å°è¯•ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ—¶é—´
                
                loop {
                    attempts += 1;
                    
                    // æ£€æŸ¥æ´»åŠ¨èŠ‚ç‚¹æ•°é‡
                    let (active_count, total_active_threads) = {
                        let active_threads_guard = active_threads_monitor.lock();
                        let active_count = active_threads_guard.values().filter(|&&active| active).count();
                        (active_count, active_threads_guard.len())
                    };
                    
                    // è·å–å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡
                    let global_active_count = get_global_active_node_count();
                    
                    // è¾“å‡ºå½“å‰æ´»åŠ¨çº¿ç¨‹ä¿¡æ¯
                    if attempts % 5 == 0 || attempts == 1 { // å‡å°‘æ—¥å¿—è¾“å‡ºé¢‘ç‡
                        println!("ğŸ”„ èŠ‚ç‚¹å¯åŠ¨ç›‘æ§: å½“å‰æ´»åŠ¨èŠ‚ç‚¹æ•°é‡: {}/{}, å…¨å±€æ´»è·ƒ: {}, å°è¯•æ¬¡æ•°: {}/{}", 
                                active_count, total_active_threads, global_active_count, attempts, max_attempts);
                    }
                    
                    // åªæœ‰å½“æ‰€æœ‰åˆå§‹èŠ‚ç‚¹éƒ½å¯åŠ¨åï¼Œæ‰æ ‡è®°ä¸ºå·²å¯åŠ¨
                    if active_count >= *max_concurrent {
                        // è®¾ç½®æ‰€æœ‰èŠ‚ç‚¹å·²å¯åŠ¨æ ‡å¿—
                        all_nodes_started_monitor.store(true, std::sync::atomic::Ordering::SeqCst);
                        println!("ğŸš€ æ‰€æœ‰åˆå§‹èŠ‚ç‚¹å·²å¯åŠ¨ ({}/{}), å¯ä»¥å¼€å§‹è½®è½¬", 
                                active_count, *max_concurrent);
                        break;
                    }
                    
                    // å¦‚æœå°è¯•æ¬¡æ•°è¿‡å¤šï¼Œå¼ºåˆ¶æ ‡è®°ä¸ºå·²å¯åŠ¨
                    if attempts >= max_attempts {
                        all_nodes_started_monitor.store(true, std::sync::atomic::Ordering::SeqCst);
                        println!("âš ï¸ èŠ‚ç‚¹å¯åŠ¨ç›‘æ§: è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•° ({}), å¼ºåˆ¶æ ‡è®°æ‰€æœ‰èŠ‚ç‚¹å·²å¯åŠ¨", max_attempts);
                        break;
                    }
                    
                    // ç­‰å¾…ä¸€æ®µæ—¶é—´åå†æ¬¡æ£€æŸ¥
                    tokio::time::sleep(std::time::Duration::from_secs(2)).await;
                }
            });
        }
    }
    
    // åˆ›å»ºèŠ‚ç‚¹ç®¡ç†å™¨é€šä¿¡é€šé“çš„å…‹éš†ï¼Œç”¨äºèŠ‚ç‚¹é€šä¿¡
    let node_tx_for_nodes = node_tx.clone();

    // è·å–æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨
    let active_nodes_list = if let Some((active_nodes, _, _, _, _, _)) = &rotation_data {
        let active_nodes_guard = active_nodes.lock();
        active_nodes_guard.clone()
    } else {
        // å¦‚æœæœªå¯ç”¨è½®è½¬ï¼Œåˆ™ä½¿ç”¨å‰actual_concurrentä¸ªèŠ‚ç‚¹
        nodes.iter().take(actual_concurrent).copied().collect()
    };
    
    println!("ğŸ”„ å‡†å¤‡æŒ‰é¡ºåºå¯åŠ¨ä»¥ä¸‹èŠ‚ç‚¹: {:?}", active_nodes_list);

    // æŒ‰åºå¯åŠ¨å„èŠ‚ç‚¹
    for (index, node_id) in active_nodes_list.iter().enumerate() {
        println!("å¯åŠ¨èŠ‚ç‚¹ {} (ç¬¬{}/{}ä¸ª)", 
                node_id, index + 1, actual_concurrent);
        
        // æ£€æŸ¥å†…å­˜å‹åŠ›ï¼Œå¦‚æœéœ€è¦åˆ™ç­‰å¾…æ›´é•¿æ—¶é—´
        if check_memory_pressure() {
            debug!("èŠ‚ç‚¹ {} å¯åŠ¨å‰æ£€æµ‹åˆ°å†…å­˜å‹åŠ›ï¼Œæ‰§è¡Œæ¸…ç†...", node_id);
            perform_memory_cleanup();
            
            // åœ¨èŠ‚ç‚¹å¯åŠ¨å‰è¿›è¡Œå†…å­˜ç¢ç‰‡æ•´ç†
            if defragmenter.should_defragment().await {
                let result = defragmenter.defragment().await;
                debug!("èŠ‚ç‚¹ {} å¯åŠ¨å‰å†…å­˜ç¢ç‰‡æ•´ç†: {:.1}% â†’ {:.1}%", 
                      node_id, result.memory_before * 100.0, result.memory_after * 100.0);
            }
            
            // é¢å¤–ç­‰å¾…è®©å†…å­˜æ¸…ç†ç”Ÿæ•ˆ
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
        
        let handle = start_node_worker(
            *node_id,
            environment.clone(),
            proxy_file.clone(),
            num_workers_per_node,
            proof_interval,
            status_callback_arc.clone(),
            event_sender.clone(),
            shutdown.resubscribe(),
            rotation_data.clone(),
            active_threads.clone(),
            node_tx_for_nodes.clone(), // ä½¿ç”¨å…‹éš†çš„é€šä¿¡é€šé“
        ).await;
        
        join_handles.push(handle);
    }
    
    // æ‰§è¡Œä¸€æ¬¡åˆå§‹åŒ–åŒæ­¥
    sync_global_active_nodes(&active_threads, max_concurrent);
    
    (event_receiver, join_handles)
}

// èŠ‚ç‚¹ç®¡ç†å™¨å‘½ä»¤æšä¸¾
#[derive(Debug)]
enum NodeManagerCommand {
    NodeStarted(u64),
    NodeStopped(u64),
}

// èŠ‚ç‚¹ç®¡ç†å™¨å‡½æ•°
async fn node_manager(
    active_nodes: Arc<Mutex<Vec<u64>>>,
    active_threads: Arc<Mutex<HashMap<u64, bool>>>,
    environment: Environment,
    proxy_file: Option<String>,
    num_workers_per_node: usize,
    proof_interval: u64,
    status_callback_arc: Option<Arc<Box<dyn Fn(u64, String) + Send + Sync + 'static>>>,
    event_sender: mpsc::Sender<Event>,
    mut shutdown: broadcast::Receiver<()>,
    mut node_rx: mpsc::Receiver<NodeManagerCommand>,
    rotation_data: Option<(Arc<Mutex<Vec<u64>>>, Arc<AtomicU64>, Arc<Vec<u64>>, Arc<std::sync::atomic::AtomicBool>, Arc<Mutex<HashMap<u64, usize>>>, usize)>,
) {
    // æå–max_concurrentå€¼ç”¨äºèŠ‚ç‚¹ç®¡ç†
    let max_concurrent = if let Some((_, _, _, _, _, max)) = &rotation_data {
        *max
    } else {
        10 // é»˜è®¤å€¼
    };
    
    // åˆ›å»ºä¸€ä¸ªé›†åˆæ¥è·Ÿè¸ªå·²ç»å¤„ç†è¿‡çš„åœæ­¢æ¶ˆæ¯ï¼Œé¿å…é‡å¤å¤„ç†
    let mut processed_stop_messages = HashSet::new();
    
    // åˆ›å»ºä¸€ä¸ªé›†åˆæ¥è·Ÿè¸ªæ­£åœ¨å¯åŠ¨çš„èŠ‚ç‚¹ï¼Œé¿å…é‡å¤å¯åŠ¨
    let mut starting_nodes = HashSet::new();
    
    // åˆ›å»ºä¸€ä¸ªæ–°çš„é€šé“ï¼Œç”¨äºèŠ‚ç‚¹å·¥ä½œçº¿ç¨‹å‘èŠ‚ç‚¹ç®¡ç†å™¨å‘é€å‘½ä»¤
    let (node_cmd_tx, mut node_cmd_rx) = mpsc::channel::<NodeManagerCommand>(100);
    
    // å®šæœŸæ£€æŸ¥å’Œæ¸…ç†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ - æ›´é¢‘ç¹æ‰§è¡Œæ¸…ç†
    let active_nodes_clone = active_nodes.clone();
    let active_threads_clone = active_threads.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(10)); // å¢åŠ åˆ°10ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œå‡å°‘é¢‘ç‡
        loop {
            interval.tick().await;
            cleanup_active_nodes(&active_nodes_clone, &active_threads_clone, max_concurrent).await;
        }
    });
    
    // å®šæœŸæ‰§è¡Œå…¨å±€èŠ‚ç‚¹è®¡æ•°åŒæ­¥
    let active_threads_for_sync = active_threads.clone();
    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(5));
        loop {
            interval.tick().await;
            sync_global_active_nodes(&active_threads_for_sync, max_concurrent);
        }
    });
    
    // è®°å½•ä¸Šæ¬¡æ£€æŸ¥æ—¶é—´ï¼Œé¿å…é¢‘ç¹æ£€æŸ¥
    let mut last_check_time = Instant::now();
    let check_interval = Duration::from_secs(5); // æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
    
    loop {
        tokio::select! {
            // å¤„ç†å…³é—­ä¿¡å·
            _ = shutdown.recv() => {
                println!("ğŸ›‘ èŠ‚ç‚¹ç®¡ç†å™¨: æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œåœæ­¢æ‰€æœ‰èŠ‚ç‚¹");
                break;
            }
            
            // å¤„ç†åŸå§‹èŠ‚ç‚¹å‘½ä»¤é€šé“
            Some(cmd) = node_rx.recv() => {
                handle_node_command(cmd, &mut processed_stop_messages, &mut starting_nodes, &active_nodes, &active_threads, &environment, &proxy_file, num_workers_per_node, proof_interval, &status_callback_arc, &event_sender, &shutdown, &node_cmd_tx, &rotation_data, max_concurrent).await;
            }
            
            // å¤„ç†æ–°åˆ›å»ºçš„èŠ‚ç‚¹å‘½ä»¤é€šé“
            Some(cmd) = node_cmd_rx.recv() => {
                handle_node_command(cmd, &mut processed_stop_messages, &mut starting_nodes, &active_nodes, &active_threads, &environment, &proxy_file, num_workers_per_node, proof_interval, &status_callback_arc, &event_sender, &shutdown, &node_cmd_tx, &rotation_data, max_concurrent).await;
            }
            
            // å®šæœŸæ£€æŸ¥æ˜¯å¦æœ‰èŠ‚ç‚¹éœ€è¦å¯åŠ¨ - æ›´çŸ­çš„æ£€æŸ¥é—´éš”
            _ = tokio::time::sleep(Duration::from_millis(100)) => {
                // æ£€æŸ¥æ˜¯å¦åˆ°äº†æ£€æŸ¥æ—¶é—´
                if last_check_time.elapsed() < check_interval {
                    continue;
                }
                
                // æ›´æ–°ä¸Šæ¬¡æ£€æŸ¥æ—¶é—´
                last_check_time = Instant::now();
                
                // æ¯æ¬¡æ£€æŸ¥å‰å¼ºåˆ¶æ‰§è¡Œæ¸…ç†ï¼Œç¡®ä¿æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨å’Œæ´»åŠ¨çº¿ç¨‹çŠ¶æ€ä¸€è‡´
                cleanup_active_nodes(&active_nodes, &active_threads, max_concurrent).await;
                
                // è·å–å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡
                let global_active_count = get_global_active_node_count();
                
                // ç¡®è®¤æ¸…ç†åçš„çŠ¶æ€
                let current_active_count = {
                    let threads_guard = active_threads.lock();
                    threads_guard.values().filter(|&&active| active).count()
                };
                
                let active_nodes_count = {
                    let nodes_guard = active_nodes.lock();
                    nodes_guard.len()
                };
                
                if VERBOSE_OUTPUT {
                    println!("ğŸ“Š èŠ‚ç‚¹ç®¡ç†å™¨: å®šæœŸæ£€æŸ¥ - å½“å‰æ´»åŠ¨èŠ‚ç‚¹æ•°é‡: {}, æ´»åŠ¨åˆ—è¡¨é•¿åº¦: {}, å…¨å±€æ´»è·ƒæ•°é‡: {}, æœ€å¤§å¹¶å‘æ•°: {}", 
                            current_active_count, active_nodes_count, global_active_count, max_concurrent);
                }
                
                // å¦‚æœæ´»åŠ¨èŠ‚ç‚¹æ•°é‡æˆ–æ´»åŠ¨åˆ—è¡¨é•¿åº¦è¶…è¿‡æœ€å¤§å¹¶å‘æ•°ï¼Œæ‰§è¡Œå¼ºåˆ¶æ¸…ç†
                if current_active_count > max_concurrent || active_nodes_count > max_concurrent || global_active_count > max_concurrent {
                    println!("âš ï¸ èŠ‚ç‚¹ç®¡ç†å™¨: çŠ¶æ€ä¸ä¸€è‡´æˆ–è¶…å‡ºé™åˆ¶ï¼Œæ‰§è¡Œå¼ºåˆ¶æ¸…ç†");
                    
                    // å¼ºåˆ¶åŒæ­¥å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
                    sync_global_active_nodes(&active_threads, max_concurrent);
                    
                    // ç„¶åæ¸…ç†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨
                    cleanup_active_nodes(&active_nodes, &active_threads, max_concurrent).await;
                }
                
                // è·å–éœ€è¦å¯åŠ¨çš„èŠ‚ç‚¹
                let nodes_to_start = get_nodes_to_start(&active_nodes, &active_threads).await;
                
                // è·å–æœ€æ–°çš„å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡
                let global_active_count = get_global_active_node_count();
                
                // ç¡®è®¤æœ€ç»ˆçŠ¶æ€
                let final_active_count = {
                    let threads_guard = active_threads.lock();
                    threads_guard.values().filter(|&&active| active).count()
                };
                
                // ä½¿ç”¨å…¨å±€è®¡æ•°å’Œæœ¬åœ°è®¡æ•°çš„è¾ƒå¤§å€¼æ¥è®¡ç®—å¯ç”¨æ§½ä½ï¼Œç¡®ä¿æ›´ä¸¥æ ¼çš„æ§åˆ¶
                let effective_active_count = std::cmp::max(global_active_count, final_active_count);
                
                // è®¡ç®—å¯ä»¥å¯åŠ¨çš„èŠ‚ç‚¹æ•°é‡
                let available_slots = if effective_active_count < max_concurrent {
                    max_concurrent - effective_active_count
                } else {
                    0
                };
                
                if available_slots > 0 && !nodes_to_start.is_empty() {
                    println!("ğŸ“Š èŠ‚ç‚¹ç®¡ç†å™¨: æœ‰ {} ä¸ªå¯ç”¨æ§½ä½ï¼Œå¯ä»¥å¯åŠ¨æ–°èŠ‚ç‚¹", available_slots);
                    
                    // åªå¯åŠ¨å¯ç”¨æ§½ä½æ•°é‡çš„èŠ‚ç‚¹
                    let nodes_to_start = nodes_to_start.into_iter()
                        .filter(|&node_id| !starting_nodes.contains(&node_id) && !is_node_globally_active(node_id))
                        .take(available_slots)
                        .collect::<Vec<_>>();
                    
                    if !nodes_to_start.is_empty() {
                        println!("ğŸš€ èŠ‚ç‚¹ç®¡ç†å™¨: å‡†å¤‡å¯åŠ¨ {} ä¸ªæ–°èŠ‚ç‚¹", nodes_to_start.len());
                        
                        // æ ‡è®°è¿™äº›èŠ‚ç‚¹ä¸ºæ­£åœ¨å¯åŠ¨
                        for &node_id in &nodes_to_start {
                            starting_nodes.insert(node_id);
                        }
                        
                        // å¯åŠ¨èŠ‚ç‚¹
                        for node_id in nodes_to_start {
                            // å†æ¬¡ç¡®è®¤å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡æœªè¶…é™
                            if get_global_active_node_count() >= max_concurrent {
                                println!("âš ï¸ èŠ‚ç‚¹ç®¡ç†å™¨: å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°ï¼Œå–æ¶ˆå¯åŠ¨å‰©ä½™èŠ‚ç‚¹");
                                break;
                            }
                            
                            // å¯åŠ¨æ–°èŠ‚ç‚¹
                            println!("ğŸš€ èŠ‚ç‚¹ç®¡ç†å™¨: å¯åŠ¨èŠ‚ç‚¹-{}", node_id);
                            
                            let handle = start_node_worker(
                                node_id,
                                environment.clone(),
                                proxy_file.clone(),
                                num_workers_per_node,
                                proof_interval,
                                status_callback_arc.clone(),
                                event_sender.clone(),
                                shutdown.resubscribe(),
                                rotation_data.clone(),
                                active_threads.clone(),
                                node_cmd_tx.clone(),
                            ).await;
                            
                            // ä¸éœ€è¦å­˜å‚¨å¥æŸ„ï¼Œå› ä¸ºå®ƒä»¬ä¼šåœ¨å®Œæˆæ—¶è‡ªåŠ¨æ¸…ç†
                            tokio::spawn(async move {
                                let _ = handle.await;
                            });
                            
                            // çŸ­æš‚ç­‰å¾…ç¡®ä¿èŠ‚ç‚¹å¯åŠ¨é€»è¾‘å®Œæˆ
                            tokio::time::sleep(Duration::from_millis(100)).await;
                        }
                    }
                }
            }
        }
    }
}

// æå–å¤„ç†èŠ‚ç‚¹å‘½ä»¤çš„é€»è¾‘ä¸ºä¸€ä¸ªå•ç‹¬çš„å‡½æ•°
async fn handle_node_command(
    cmd: NodeManagerCommand,
    processed_stop_messages: &mut HashSet<u64>,
    starting_nodes: &mut HashSet<u64>,
    active_nodes: &Arc<Mutex<Vec<u64>>>,
    active_threads: &Arc<Mutex<HashMap<u64, bool>>>,
    environment: &Environment,
    proxy_file: &Option<String>,
    num_workers_per_node: usize,
    proof_interval: u64,
    status_callback_arc: &Option<Arc<Box<dyn Fn(u64, String) + Send + Sync + 'static>>>,
    event_sender: &mpsc::Sender<Event>,
    shutdown: &broadcast::Receiver<()>,
    node_cmd_tx: &mpsc::Sender<NodeManagerCommand>,
    rotation_data: &Option<(Arc<Mutex<Vec<u64>>>, Arc<AtomicU64>, Arc<Vec<u64>>, Arc<std::sync::atomic::AtomicBool>, Arc<Mutex<HashMap<u64, usize>>>, usize)>,
    max_concurrent: usize,
) {
    match cmd {
        NodeManagerCommand::NodeStarted(node_id) => {
            // èŠ‚ç‚¹å·²å¯åŠ¨ï¼Œä»å¯åŠ¨ä¸­åˆ—è¡¨ç§»é™¤
            starting_nodes.remove(&node_id);
        }
        NodeManagerCommand::NodeStopped(node_id) => {
            // æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™ä¸ªåœæ­¢æ¶ˆæ¯
            if processed_stop_messages.contains(&node_id) {
                return;
            }
            
            // æ ‡è®°ä¸ºå·²å¤„ç†
            processed_stop_messages.insert(node_id);
            
            // åœ¨ä¸€æ®µæ—¶é—´åç§»é™¤å·²å¤„ç†æ ‡è®°ï¼Œå…è®¸å°†æ¥å†æ¬¡å¤„ç†è¯¥èŠ‚ç‚¹çš„åœæ­¢æ¶ˆæ¯
            let node_id_clone = node_id;
            let processed_messages_clone = Arc::new(Mutex::new(processed_stop_messages.clone()));
            tokio::spawn(async move {
                tokio::time::sleep(Duration::from_secs(5)).await;
                let mut guard = processed_messages_clone.lock();
                guard.remove(&node_id_clone);
            });
            
            println!("ğŸ›‘ èŠ‚ç‚¹ç®¡ç†å™¨: èŠ‚ç‚¹-{} å·²åœæ­¢", node_id);
            
            // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
            {
                let mut threads_guard = active_threads.lock();
                threads_guard.insert(node_id, false);
            }
            
            println!("ğŸ”„ èŠ‚ç‚¹ç®¡ç†å™¨: èŠ‚ç‚¹-{} å·²åœæ­¢ï¼Œå‡†å¤‡å¯åŠ¨æ–°èŠ‚ç‚¹", node_id);
            
            // è·å–éœ€è¦å¯åŠ¨çš„èŠ‚ç‚¹
            let nodes_to_start = get_nodes_to_start(active_nodes, active_threads).await;
            
            // ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§å¹¶å‘æ•°
            let current_active_count = {
                let threads_guard = active_threads.lock();
                threads_guard.values().filter(|&&active| active).count()
            };
            
            // è®¡ç®—å¯ä»¥å¯åŠ¨çš„èŠ‚ç‚¹æ•°é‡
            let available_slots = if current_active_count < max_concurrent {
                max_concurrent - current_active_count
            } else {
                0
            };
            
            if available_slots > 0 {
                // åªå¯åŠ¨å¯ç”¨æ§½ä½æ•°é‡çš„èŠ‚ç‚¹
                let nodes_to_start = nodes_to_start.into_iter()
                    .filter(|&node_id| !starting_nodes.contains(&node_id))
                    .take(available_slots)
                    .collect::<Vec<_>>();
                
                // æ ‡è®°è¿™äº›èŠ‚ç‚¹ä¸ºæ­£åœ¨å¯åŠ¨
                for &node_id in &nodes_to_start {
                    starting_nodes.insert(node_id);
                }
                
                // å¯åŠ¨èŠ‚ç‚¹
                for node_id in nodes_to_start {
                    // å¯åŠ¨æ–°èŠ‚ç‚¹
                    println!("ğŸš€ èŠ‚ç‚¹ç®¡ç†å™¨: å¯åŠ¨èŠ‚ç‚¹-{}", node_id);
                    
                    let handle = start_node_worker(
                        node_id,
                        environment.clone(),
                        proxy_file.clone(),
                        num_workers_per_node,
                        proof_interval,
                        status_callback_arc.clone(),
                        event_sender.clone(),
                        shutdown.resubscribe(),
                        rotation_data.clone(),
                        active_threads.clone(),
                        node_cmd_tx.clone(),
                    ).await;
                    
                    // ä¸éœ€è¦å­˜å‚¨å¥æŸ„ï¼Œå› ä¸ºå®ƒä»¬ä¼šåœ¨å®Œæˆæ—¶è‡ªåŠ¨æ¸…ç†
                    tokio::spawn(async move {
                        let _ = handle.await;
                    });
                }
            } else {
                if VERBOSE_OUTPUT {
                    println!("âš ï¸ èŠ‚ç‚¹ç®¡ç†å™¨: å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•° {}, æš‚ä¸å¯åŠ¨æ–°èŠ‚ç‚¹", max_concurrent);
                }
            }
        }
    }
}

// è·å–éœ€è¦å¯åŠ¨çš„èŠ‚ç‚¹åˆ—è¡¨
async fn get_nodes_to_start(
    active_nodes: &Arc<Mutex<Vec<u64>>>,
    active_threads: &Arc<Mutex<HashMap<u64, bool>>>,
) -> Vec<u64> {
    // è·å–éœ€è¦å¯åŠ¨çš„èŠ‚ç‚¹åˆ—è¡¨å’Œæ´»åŠ¨èŠ‚ç‚¹æ•°é‡
    let to_start;
    let active_count;
    
    // ä½¿ç”¨ä½œç”¨åŸŸç¡®ä¿é”åœ¨æ“ä½œå®Œæˆåé‡Šæ”¾
    {
        let active_nodes_guard = active_nodes.lock();
        let active_threads_guard = active_threads.lock();
        
        // æ£€æŸ¥æ¯ä¸ªæ´»åŠ¨èŠ‚ç‚¹ï¼Œæ‰¾å‡ºæ²¡æœ‰è¿è¡Œçš„èŠ‚ç‚¹
        to_start = active_nodes_guard.iter()
            .filter(|&&node_id| {
                !active_threads_guard.get(&node_id).copied().unwrap_or(false)
            })
            .copied()
            .collect::<Vec<u64>>();
        
        // è®¡ç®—å½“å‰æ´»åŠ¨èŠ‚ç‚¹æ•°é‡
        active_count = active_threads_guard.iter()
            .filter(|pair| *pair.1)
            .count();
    }
    
    if !to_start.is_empty() {
        println!("ğŸ”„ èŠ‚ç‚¹ç®¡ç†å™¨: å‘ç° {} ä¸ªæœªè¿è¡Œçš„èŠ‚ç‚¹éœ€è¦å¯åŠ¨: {:?}", to_start.len(), to_start);
        println!("ğŸ”„ èŠ‚ç‚¹ç®¡ç†å™¨: å½“å‰æ´»åŠ¨èŠ‚ç‚¹æ•°é‡: {}", active_count);
    }
    
    to_start
}

// è½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„å‡½æ•°
async fn rotate_to_next_node(
    node_id: u64,
    rotation_data: &Option<(Arc<Mutex<Vec<u64>>>, Arc<AtomicU64>, Arc<Vec<u64>>, Arc<std::sync::atomic::AtomicBool>, Arc<Mutex<HashMap<u64, usize>>>, usize)>,
    reason: &str,
    node_tx: &mpsc::Sender<NodeManagerCommand>,
) -> (bool, Option<String>) {
    if VERBOSE_OUTPUT {
        println!("\nğŸ“£ èŠ‚ç‚¹-{}: å°è¯•è½®è½¬ (åŸå› : {})", node_id, reason);
    }
    
    // ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆç§»é™¤å½“å‰èŠ‚ç‚¹
    remove_global_active_node(node_id);
    if VERBOSE_OUTPUT {
        println!("ğŸŒ èŠ‚ç‚¹-{}: å·²ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆç§»é™¤", node_id);
    }
    
    if let Some((active_nodes, _next_node_index, all_nodes, all_nodes_started, node_indices, max_concurrent)) = rotation_data {
        // æ£€æŸ¥æ‰€æœ‰åˆå§‹èŠ‚ç‚¹æ˜¯å¦å·²å¯åŠ¨
        if !all_nodes_started.load(std::sync::atomic::Ordering::SeqCst) {
            println!("âš ï¸ èŠ‚ç‚¹-{}: æ‰€æœ‰åˆå§‹èŠ‚ç‚¹å°šæœªå¯åŠ¨å®Œæˆï¼Œæš‚ä¸è½®è½¬", node_id);
            return (false, Some(format!("âš ï¸ èŠ‚ç‚¹-{}: æ‰€æœ‰åˆå§‹èŠ‚ç‚¹å°šæœªå¯åŠ¨å®Œæˆï¼Œæš‚ä¸è½®è½¬", node_id)));
        }
        
        // è·å–å½“å‰æ´»è·ƒèŠ‚ç‚¹æ•°é‡ï¼ˆä»…ç”¨äºæ—¥å¿—è®°å½•ï¼‰
        let current_active_count = {
            let threads_guard = GLOBAL_ACTIVE_NODES.lock();
            threads_guard.len()
        };
        
        println!("ğŸ“Š èŠ‚ç‚¹-{}: å½“å‰æ´»è·ƒèŠ‚ç‚¹æ•°é‡: {}/{}", node_id, current_active_count, *max_concurrent);
        
        // è·å–å½“å‰èŠ‚ç‚¹çš„ç´¢å¼•
        let node_idx_opt = {
            let node_indices_guard = node_indices.lock();
            node_indices_guard.get(&node_id).copied()
        };
        
        if let Some(node_idx) = node_idx_opt {
            // è®¡ç®—ä¸‹ä¸€ä¸ªèŠ‚ç‚¹çš„ç´¢å¼•ï¼šå½“å‰ç´¢å¼• + max_concurrentï¼Œä»¥ç¡®ä¿èŠ‚ç‚¹åˆ†æ•£
            let jump_distance = *max_concurrent;
            let next_idx = (node_idx + jump_distance) % all_nodes.len();
            let next_node_id = all_nodes[next_idx];
            
            // ç¡®ä¿ä¸ä¼šè½®è½¬åˆ°è‡ªå·±
            let final_next_idx = if next_node_id == node_id && all_nodes.len() > 1 {
                // å¦‚æœè½®è½¬åˆ°è‡ªå·±ä¸”æœ‰å…¶ä»–èŠ‚ç‚¹å¯ç”¨ï¼Œåˆ™é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                let alternative_idx = (next_idx + 1) % all_nodes.len();
                println!("âš ï¸ èŠ‚ç‚¹-{}: é¿å…è½®è½¬åˆ°è‡ªå·±ï¼Œæ”¹ä¸ºä½¿ç”¨ç´¢å¼• {}", node_id, alternative_idx);
                alternative_idx
            } else {
                next_idx
            };
            
            let final_next_node_id = all_nodes[final_next_idx];
            
            println!("ğŸ“Š èŠ‚ç‚¹-{}: å½“å‰ç´¢å¼•: {}, ä¸‹ä¸€ä¸ªç´¢å¼•: {}, æ€»èŠ‚ç‚¹æ•°: {}", 
                    node_id, node_idx, final_next_idx, all_nodes.len());
            println!("ğŸ”„ èŠ‚ç‚¹-{}: å°†è½®è½¬åˆ°èŠ‚ç‚¹-{} (ç´¢å¼•: {})", node_id, final_next_node_id, final_next_idx);
            
            // æ£€æŸ¥æ–°èŠ‚ç‚¹æ˜¯å¦å·²ç»åœ¨å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­
            if is_node_globally_active(final_next_node_id) {
                println!("âš ï¸ èŠ‚ç‚¹-{}: æ–°èŠ‚ç‚¹-{} å·²ç»åœ¨å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ï¼Œä¸é‡å¤æ·»åŠ ", 
                        node_id, final_next_node_id);
                
                // é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å½“å‰èŠ‚ç‚¹å·²åœæ­¢
                let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
                
                return (true, Some(format!("âš ï¸ èŠ‚ç‚¹-{}: æ–°èŠ‚ç‚¹-{} å·²åœ¨å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ï¼Œè·³è¿‡æ·»åŠ ", 
                                       node_id, final_next_node_id)));
            }
            
            // è·å–å½“å‰æ´»è·ƒèŠ‚ç‚¹åˆ—è¡¨å¹¶æ‰“å°ï¼ˆåœ¨ä¸€ä¸ªç‹¬ç«‹çš„ä½œç”¨åŸŸå†…ï¼‰
            {
                let active_nodes_guard = active_nodes.lock();
                println!("ğŸ“‹ èŠ‚ç‚¹-{}: è½®è½¬å‰æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨: {:?}", node_id, *active_nodes_guard);
                println!("ğŸ“‹ èŠ‚ç‚¹-{}: æ´»åŠ¨èŠ‚ç‚¹æ•°é‡: {}, æœ€å¤§å¹¶å‘æ•°: {}", node_id, active_nodes_guard.len(), *max_concurrent);
                // é”åœ¨è¿™é‡Œé‡Šæ”¾
            }
            
            // æ›´æ–°æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨
            {
                let mut active_nodes_guard = active_nodes.lock();
                
                // æŸ¥æ‰¾å½“å‰èŠ‚ç‚¹åœ¨æ´»åŠ¨åˆ—è¡¨ä¸­çš„ä½ç½®
                let pos = active_nodes_guard.iter().position(|&id| id == node_id);
                
                if let Some(pos) = pos {
                    // å½“å‰èŠ‚ç‚¹åœ¨åˆ—è¡¨ä¸­ï¼Œç›´æ¥æ›¿æ¢
                    println!("âœ… èŠ‚ç‚¹-{}: åœ¨æ´»åŠ¨åˆ—è¡¨ä¸­æ‰¾åˆ°ä½ç½® {}", node_id, pos);
                    active_nodes_guard[pos] = final_next_node_id;
                    println!("âœ… èŠ‚ç‚¹-{}: å·²æ›¿æ¢ä¸ºèŠ‚ç‚¹-{}", node_id, final_next_node_id);
                    
                    // ç¡®ä¿å½“å‰èŠ‚ç‚¹å·²ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ç§»é™¤
                    remove_global_active_node(node_id);
                    println!("ğŸŒ èŠ‚ç‚¹-{}: å·²ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ç§»é™¤", node_id);
                    
                    // å°†æ–°èŠ‚ç‚¹æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
                    add_global_active_node(final_next_node_id);
                    println!("ğŸŒ èŠ‚ç‚¹-{}: æ–°èŠ‚ç‚¹-{} å·²æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ", node_id, final_next_node_id);
                    
                    // åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥å¯åŠ¨æ–°èŠ‚ç‚¹
                    println!("ğŸš€ èŠ‚ç‚¹-{}: æ­£åœ¨è§¦å‘æ–°èŠ‚ç‚¹-{} çš„å¯åŠ¨", node_id, final_next_node_id);
                } else {
                    // å½“å‰èŠ‚ç‚¹ä¸åœ¨åˆ—è¡¨ä¸­
                    println!("\nâš ï¸ èŠ‚ç‚¹-{}: æœªåœ¨æ´»åŠ¨åˆ—è¡¨ä¸­æ‰¾åˆ°", node_id);
                    
                    // å¦‚æœåˆ—è¡¨æœªæ»¡ï¼Œå°è¯•æ·»åŠ æ–°èŠ‚ç‚¹
                    if active_nodes_guard.len() < *max_concurrent {
                        active_nodes_guard.push(final_next_node_id);
                        println!("âœ… èŠ‚ç‚¹-{}: å·²æ·»åŠ æ–°èŠ‚ç‚¹-{} åˆ°æ´»åŠ¨åˆ—è¡¨", node_id, final_next_node_id);
                        
                        // å°†æ–°èŠ‚ç‚¹æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
                        add_global_active_node(final_next_node_id);
                        println!("ğŸŒ èŠ‚ç‚¹-{}: æ–°èŠ‚ç‚¹-{} å·²æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ", node_id, final_next_node_id);
                    } else {
                        // åˆ—è¡¨å·²æ»¡ï¼Œå°è¯•æ›¿æ¢ä¸€ä¸ªèŠ‚ç‚¹
                        println!("âš ï¸ èŠ‚ç‚¹-{}: æ´»åŠ¨èŠ‚ç‚¹æ•°é‡å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•° {}, å°è¯•æ›¿æ¢ä¸€ä¸ªèŠ‚ç‚¹", node_id, *max_concurrent);
                        
                        // é€‰æ‹©ç¬¬ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œæ›¿æ¢
                        if !active_nodes_guard.is_empty() {
                            let replaced_node = active_nodes_guard[0];
                            active_nodes_guard[0] = final_next_node_id;
                            println!("âœ… èŠ‚ç‚¹-{}: å·²æ›¿æ¢èŠ‚ç‚¹-{} ä¸ºèŠ‚ç‚¹-{}", node_id, replaced_node, final_next_node_id);
                            
                            // ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ç§»é™¤è¢«æ›¿æ¢çš„èŠ‚ç‚¹
                            remove_global_active_node(replaced_node);
                            
                            // å°†æ–°èŠ‚ç‚¹æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
                            add_global_active_node(final_next_node_id);
                            println!("ğŸŒ èŠ‚ç‚¹-{}: æ–°èŠ‚ç‚¹-{} å·²æ·»åŠ åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ", node_id, final_next_node_id);
                            
                            // åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥å¯åŠ¨æ–°èŠ‚ç‚¹
                            println!("ğŸš€ èŠ‚ç‚¹-{}: æ­£åœ¨è§¦å‘æ–°èŠ‚ç‚¹-{} çš„å¯åŠ¨", node_id, final_next_node_id);
                        } else {
                            println!("âŒ èŠ‚ç‚¹-{}: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ›¿æ¢", node_id);
                            return (false, Some(format!("âŒ èŠ‚ç‚¹-{}: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ›¿æ¢", node_id)));
                        }
                    }
                }
                
                // æœ€åå†æ¬¡ç¡®ä¿æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸è¶…è¿‡æœ€å¤§å¹¶å‘æ•°
                if active_nodes_guard.len() > *max_concurrent {
                    println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åå¼ºåˆ¶æ£€æŸ¥ - æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨è¶…å‡ºé™åˆ¶ ({} > {}), è¿›è¡Œæˆªæ–­", 
                            node_id, active_nodes_guard.len(), *max_concurrent);
                    active_nodes_guard.truncate(*max_concurrent);
                    println!("âœ… èŠ‚ç‚¹-{}: å·²å¼ºåˆ¶æˆªæ–­æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨è‡³ {} ä¸ªèŠ‚ç‚¹", node_id, active_nodes_guard.len());
                }
            }
            
            // é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å½“å‰èŠ‚ç‚¹å·²åœæ­¢
            println!("ğŸ“£ èŠ‚ç‚¹-{}: æ­£åœ¨é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨èŠ‚ç‚¹åœæ­¢", node_id);
            
            // æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œç¡®ä¿æ¶ˆæ¯èƒ½å¤Ÿå‘é€æˆåŠŸ
            let mut retry_count = 0;
            let max_retries = 3;
            
            // ä¸å†éœ€è¦successå˜é‡ï¼Œç›´æ¥åŸºäºé‡è¯•æ¬¡æ•°æ§åˆ¶å¾ªç¯
            while retry_count < max_retries {
                // ç¡®ä¿æ¶ˆæ¯å‘é€æˆåŠŸ - ä½¿ç”¨è¶…æ—¶æœºåˆ¶
                match tokio::time::timeout(
                    std::time::Duration::from_secs(2), 
                    node_tx.send(NodeManagerCommand::NodeStopped(node_id))
                ).await {
                    Ok(Ok(_)) => {
                        println!("ğŸ“£ èŠ‚ç‚¹-{}: å·²æˆåŠŸé€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨èŠ‚ç‚¹åœæ­¢", node_id);
                        // æˆåŠŸå‘é€æ¶ˆæ¯ï¼Œç›´æ¥é€€å‡ºå¾ªç¯
                        break;
                    },
                    Ok(Err(e)) => {
                        retry_count += 1;
                        println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å¤±è´¥ (å°è¯• {}/{}): {}", node_id, retry_count, max_retries, e);
                        
                        if retry_count >= max_retries {
                            println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°", node_id);
                        } else {
                            // çŸ­æš‚ç­‰å¾…åé‡è¯•
                            tokio::time::sleep(std::time::Duration::from_millis(100)).await;
                        }
                    },
                    Err(_) => {
                        retry_count += 1;
                        println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨è¶…æ—¶ (å°è¯• {}/{})", node_id, retry_count, max_retries);
                        
                        if retry_count >= max_retries {
                            println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨è¶…æ—¶ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°", node_id);
                        } else {
                            // çŸ­æš‚ç­‰å¾…åé‡è¯•
                            tokio::time::sleep(std::time::Duration::from_millis(100)).await;
                        }
                    },
                }
            }
            
            // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ´»åŠ¨çº¿ç¨‹çŠ¶æ€æ˜ å°„ï¼Œç”¨äºæ¸…ç†
            let active_threads_for_cleanup = Arc::new(Mutex::new(HashMap::<u64, bool>::new()));
            
            // å°†æ–°èŠ‚ç‚¹æ ‡è®°ä¸ºæ´»è·ƒçŠ¶æ€
            {
                let mut threads_guard = active_threads_for_cleanup.lock();
                threads_guard.insert(final_next_node_id, true);
            }
            
            // å¼ºåˆ¶æ‰§è¡Œä¸€æ¬¡èŠ‚ç‚¹æ¸…ç†ï¼Œç¡®ä¿çŠ¶æ€ä¸€è‡´
            cleanup_active_nodes(active_nodes, &active_threads_for_cleanup, *max_concurrent).await;
            
            // ç¡®ä¿æ–°èŠ‚ç‚¹åœ¨å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­
            if !is_node_globally_active(final_next_node_id) {
                add_global_active_node(final_next_node_id);
                println!("ğŸŒ èŠ‚ç‚¹-{}: ç¡®ä¿æ–°èŠ‚ç‚¹-{} åœ¨å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­", node_id, final_next_node_id);
            }
            
            // ç”ŸæˆçŠ¶æ€æ¶ˆæ¯
            let status_msg = format!("ğŸ”„ èŠ‚ç‚¹è½®è½¬: {} â†’ {} (åŸå› : {}) - å½“å‰èŠ‚ç‚¹å·²å¤„ç†å®Œæ¯•", node_id, final_next_node_id, reason);
            
            println!("\n{}\n", status_msg); // æ·»åŠ æ˜æ˜¾çš„æ§åˆ¶å°è¾“å‡º
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿èŠ‚ç‚¹ç®¡ç†å™¨æœ‰æ—¶é—´å¤„ç†æ¶ˆæ¯
            tokio::time::sleep(std::time::Duration::from_millis(50)).await;
            
            return (true, Some(status_msg));
        } else {
            println!("âš ï¸ èŠ‚ç‚¹-{}: æœªæ‰¾åˆ°èŠ‚ç‚¹ç´¢å¼•ï¼Œæ— æ³•è½®è½¬", node_id);
            return (false, None);
        }
    } else {
        // è½®è½¬åŠŸèƒ½æœªå¯ç”¨
        println!("\nâš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åŠŸèƒ½æœªå¯ç”¨æˆ–é…ç½®é”™è¯¯ï¼Œæ— æ³•è½®è½¬ (åŸå› : {})\n", node_id, reason);
    }
    println!("âŒ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥", node_id);
    (false, None)
}

// å¯åŠ¨å•ä¸ªèŠ‚ç‚¹å·¥ä½œçº¿ç¨‹
async fn start_node_worker(
    node_id: u64,
    environment: Environment,
    proxy_file: Option<String>,
    num_workers_per_node: usize,
    proof_interval: u64,
    status_callback_arc: Option<Arc<Box<dyn Fn(u64, String) + Send + Sync + 'static>>>,
    event_sender: mpsc::Sender<Event>,
    shutdown: broadcast::Receiver<()>,
    rotation_data: Option<(Arc<Mutex<Vec<u64>>>, Arc<AtomicU64>, Arc<Vec<u64>>, Arc<std::sync::atomic::AtomicBool>, Arc<Mutex<HashMap<u64, usize>>>, usize)>,
    active_threads: Arc<Mutex<HashMap<u64, bool>>>,
    node_tx: mpsc::Sender<NodeManagerCommand>,
) -> JoinHandle<()> {
    // è·å–æœ€å¤§å¹¶å‘æ•°
    let max_concurrent = if let Some((_, _, _, _, _, max)) = &rotation_data {
        *max
    } else {
        10 // é»˜è®¤å€¼
    };

    // å…¨å±€å¹¶å‘æ£€æŸ¥ - å¦‚æœå·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°ä¸”è¯¥èŠ‚ç‚¹ä¸åœ¨æ´»è·ƒåˆ—è¡¨ä¸­ï¼Œåˆ™ä¸å¯åŠ¨
    let global_active_count = get_global_active_node_count();
    if global_active_count >= max_concurrent && !is_node_globally_active(node_id) {
        println!("âš ï¸ èŠ‚ç‚¹-{}: å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡ ({}) å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•° ({}), æ‹’ç»å¯åŠ¨", 
                node_id, global_active_count, max_concurrent);
                
        // ä½¿ç”¨ArcåŒ…è£…çš„å›è°ƒ
        if let Some(callback_arc) = &status_callback_arc {
            callback_arc(node_id, format!("æ‹’ç»å¯åŠ¨: å·²è¾¾åˆ°æœ€å¤§å¹¶å‘æ•° {}", max_concurrent));
        }
        
        // è¿”å›ä¸€ä¸ªå·²å®Œæˆçš„JoinHandle
        return tokio::spawn(async move {
            println!("ğŸ›‘ èŠ‚ç‚¹-{}: å¯åŠ¨è¢«æ‹’ç»ï¼Œè¿”å›ç©ºä»»åŠ¡", node_id);
        });
    }

    // è·å–å¯†é’¥
    let signing_key = match crate::key_manager::load_or_generate_signing_key() {
        Ok(key) => key,
        Err(e) => {
            warn!("èŠ‚ç‚¹ {} åŠ è½½ç­¾åå¯†é’¥å¤±è´¥: {}", node_id, e);
            // ä½¿ç”¨ArcåŒ…è£…çš„å›è°ƒ
            if let Some(callback_arc) = &status_callback_arc {
                callback_arc(node_id, format!("åŠ è½½å¯†é’¥å¤±è´¥: {}", e));
            }
            
            // è¿”å›ä¸€ä¸ªå·²å®Œæˆçš„JoinHandle
            return tokio::spawn(async {});
        }
    };
    
    // ä½¿ç”¨å¢å¼ºç‰ˆå®¢æˆ·ç«¯
    let enhanced_orchestrator = if let Some(ref proxy_file) = proxy_file {
        EnhancedOrchestratorClient::new_with_proxy(environment.clone(), Some(proxy_file.as_str()))
    } else {
        EnhancedOrchestratorClient::new(environment.clone())
    };
    
    let client_id = format!("{:x}", md5::compute(node_id.to_le_bytes()));

    // ä¸ºæ¯ä¸ªä»»åŠ¡å…‹éš†ArcåŒ…è£…çš„å›è°ƒ
    let node_callback = match &status_callback_arc {
        Some(callback_arc) => {
            // å…‹éš†Arcï¼Œä¸æ˜¯å†…éƒ¨çš„å›è°ƒå‡½æ•°
            let callback_arc_clone = Arc::clone(callback_arc);
            // åˆ›å»ºä¸€ä¸ªæ–°çš„é—­åŒ…ï¼Œæ•è·Arcå…‹éš†
            Some(Box::new(move |node_id: u64, status: String| {
                callback_arc_clone(node_id, status);
            }) as Box<dyn Fn(u64, String) + Send + Sync + 'static>)
        }
        None => None
    };
    
    let event_sender_clone = event_sender.clone();
    let node_tx_clone = node_tx.clone();
    let active_threads_clone = active_threads.clone();
    
    // æ›´æ–°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
    add_global_active_node(node_id);
    
    // åœ¨spawningå‰ï¼Œé¢„å…ˆæ›´æ–°æ´»åŠ¨çº¿ç¨‹çŠ¶æ€
    {
        // æ›´æ–°æ´»åŠ¨çº¿ç¨‹çŠ¶æ€
        let mut active_threads_guard = active_threads.lock();
        active_threads_guard.insert(node_id, true);
        // é”åœ¨è¿™é‡Œé‡Šæ”¾
    }
    
    // å…ˆå‘é€èŠ‚ç‚¹å¯åŠ¨é€šçŸ¥
    let node_tx_for_notify = node_tx.clone();
    let notify_future = node_tx_for_notify.send(NodeManagerCommand::NodeStarted(node_id));
    
    // ç­‰å¾…é€šçŸ¥å®Œæˆ
    match tokio::time::timeout(Duration::from_secs(2), notify_future).await {
        Ok(Ok(_)) => println!("ğŸ“£ èŠ‚ç‚¹-{}: å·²æˆåŠŸé€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨èŠ‚ç‚¹å¯åŠ¨", node_id),
        Ok(Err(e)) => println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å¯åŠ¨å¤±è´¥: {}", node_id, e),
        Err(_) => println!("âš ï¸ èŠ‚ç‚¹-{}: é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å¯åŠ¨è¶…æ—¶", node_id),
    }
    
    // å¯åŠ¨èŠ‚ç‚¹å·¥ä½œçº¿ç¨‹
    let handle = tokio::spawn(async move {
        // è¿è¡ŒèŠ‚ç‚¹
        run_memory_optimized_node(
            node_id,
            signing_key,
            enhanced_orchestrator,
            num_workers_per_node,
            proof_interval,
            environment,
            client_id,
            shutdown,
            node_callback,
            event_sender_clone,
            rotation_data,
            active_threads_clone,
            node_tx_clone,
        ).await;
        
        // èŠ‚ç‚¹å®Œæˆæ—¶ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ç§»é™¤
        remove_global_active_node(node_id);
        println!("ğŸ”´ èŠ‚ç‚¹-{}: å·²ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸­ç§»é™¤", node_id);
    });
    
    handle
}

/// å†…å­˜ä¼˜åŒ–çš„å•èŠ‚ç‚¹è¿è¡Œå‡½æ•° - åŒ…å«429é”™è¯¯å¤„ç†å’Œé”™è¯¯æ¢å¤åŠŸèƒ½
async fn run_memory_optimized_node(
    node_id: u64,
    signing_key: SigningKey,
    orchestrator: EnhancedOrchestratorClient,
    _num_workers: usize,
    proof_interval: u64,
    environment: Environment,
    client_id: String,
    mut shutdown: broadcast::Receiver<()>,
    status_callback: Option<Box<dyn Fn(u64, String) + Send + Sync + 'static>>,
    event_sender: mpsc::Sender<Event>,
    rotation_data: Option<(Arc<Mutex<Vec<u64>>>, Arc<AtomicU64>, Arc<Vec<u64>>, Arc<std::sync::atomic::AtomicBool>, Arc<Mutex<HashMap<u64, usize>>>, usize)>,
    _active_threads: Arc<Mutex<HashMap<u64, bool>>>,
    node_tx: mpsc::Sender<NodeManagerCommand>,
) {
    // åˆ›å»ºä¸€ä¸ªåœæ­¢æ ‡å¿—ï¼Œç”¨äºå¼ºåˆ¶é€€å‡ºå¾ªç¯
    let should_stop = Arc::new(AtomicBool::new(false));
    let should_stop_clone = should_stop.clone();
    
    // åˆ›å»ºä¸€ä¸ªä»»åŠ¡æ¥ç›‘å¬åœæ­¢ä¿¡å·
    tokio::spawn(async move {
        tokio::time::sleep(std::time::Duration::from_secs(1)).await;
        should_stop_clone.store(true, std::sync::atomic::Ordering::SeqCst);
    });
    
    const MAX_SUBMISSION_RETRIES: usize = 8; // å¢åŠ åˆ°8æ¬¡ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹429é”™è¯¯
    const MAX_TASK_RETRIES: usize = 5; // å¢åŠ åˆ°5æ¬¡
    const MAX_429_RETRIES: usize = 12; // ä¸“é—¨é’ˆå¯¹429é”™è¯¯çš„é‡è¯•æ¬¡æ•°
    const MAX_CONSECUTIVE_429S_BEFORE_ROTATION: u32 = 0; // è¿ç»­429é”™è¯¯è¾¾åˆ°æ­¤æ•°é‡æ—¶è½®è½¬ï¼ˆæ”¹ä¸º0ï¼Œç¡®ä¿ç«‹å³è½®è½¬ï¼‰
    let mut _consecutive_failures = 0; // æ”¹ä¸º_consecutive_failures
    let mut proof_count = 0;
    let mut consecutive_429s = 0; // è·Ÿè¸ªè¿ç»­429é”™è¯¯
    
    // ä½¿ç”¨ä¼ å…¥çš„äº‹ä»¶å‘é€å™¨
    let event_sender = event_sender.clone();
    
    // åˆ›å»ºèŠ‚ç‚¹é€Ÿç‡é™åˆ¶è·Ÿè¸ªå™¨
    let rate_limit_tracker = online::NodeRateLimitTracker::new();
    
    // åˆ›å»ºevent_senderçš„å…‹éš†ï¼Œä»¥ä¾¿åœ¨é—­åŒ…å’Œåç»­ä»£ç ä¸­ä½¿ç”¨
    let event_sender_for_closure = event_sender.clone();
    
    // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
    let update_status = move |status: String| {
        if let Some(callback) = &status_callback {
            callback(node_id, status.clone());
        }
    };
    
    // å‘é€äº‹ä»¶åˆ°UI
    let _send_event = move |msg: String, event_type: crate::events::EventType| {
        let event_sender = event_sender_for_closure.clone();
        tokio::spawn(async move {
            let _ = event_sender
                .send(Event::proof_submitter(msg, event_type))
                .await;
        });
    };
    
    update_status(format!("ğŸš€ å¯åŠ¨ä¸­"));
    
    // é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨èŠ‚ç‚¹å·²å¯åŠ¨
    let _ = node_tx.send(NodeManagerCommand::NodeStarted(node_id)).await;
    
    // ä¸å†éœ€è¦é¢å¤–è¾“å‡ºå¤§é‡å¯åŠ¨æ—¥å¿—
    println!("ğŸŒ èŠ‚ç‚¹-{}: å¯åŠ¨å¹¶è¿è¡Œä¸­", node_id);
    
    loop {
        // æ£€æŸ¥åœæ­¢æ ‡å¿—
        if should_stop.load(std::sync::atomic::Ordering::SeqCst) {
            update_status("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...".to_string());
            // é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å½“å‰èŠ‚ç‚¹å·²åœæ­¢
            let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
            println!("ğŸ›‘ èŠ‚ç‚¹-{}: å¼ºåˆ¶åœæ­¢", node_id);
            break;
        }
        
        // é¦–å…ˆæ£€æŸ¥å…³é—­ä¿¡å·
        if shutdown.try_recv().is_ok() {
            update_status("å·²åœæ­¢".to_string());
            // é€šçŸ¥èŠ‚ç‚¹ç®¡ç†å™¨å½“å‰èŠ‚ç‚¹å·²åœæ­¢
            let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
            break;
        }
        
        // æ£€æŸ¥å†…å­˜å‹åŠ›
        if check_memory_pressure() {
            update_status("âš ï¸ æ£€æµ‹åˆ°å†…å­˜å‹åŠ›ï¼Œæ‰§è¡Œæ¸…ç†...".to_string());
            perform_memory_cleanup();
            tokio::time::sleep(Duration::from_millis(500)).await;
        }
        
        // è·å–å†…å­˜ç¢ç‰‡æ•´ç†å™¨çŠ¶æ€
        let defragmenter = get_defragmenter();
        if defragmenter.should_defragment().await {
            update_status(format!("ğŸ§¹ æ‰§è¡Œå†…å­˜ç¢ç‰‡æ•´ç†..."));
            let result = defragmenter.defragment().await;
            update_status(format!("å†…å­˜: {:.1}% â†’ {:.1}% (é‡Šæ”¾ {:.1}%)",
                             result.memory_before * 100.0,
                             result.memory_after * 100.0,
                             result.memory_freed_percentage()));
        }
        
        let timestamp = get_timestamp_efficient();
        let mut attempt = 1;
        let _success = false; // ç§»é™¤å¯å˜æ€§ï¼Œä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€æ ‡è®°
        
        // å°è¯•è·å–ä»»åŠ¡å¹¶ç”Ÿæˆè¯æ˜
        while attempt <= MAX_TASK_RETRIES {
            update_status(format!("[{}] è·å–ä»»åŠ¡ ({}/{})", timestamp, attempt, MAX_TASK_RETRIES));
            
            let verifying_key = signing_key.verifying_key();
            match orchestrator.get_task(&node_id.to_string(), &verifying_key).await {
                Ok(task) => {
                    // æˆåŠŸè·å–ä»»åŠ¡ï¼Œé‡ç½®429è®¡æ•°
                    rate_limit_tracker.reset_429_count(node_id).await;
                    consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                    
                    // è·å–èŠ‚ç‚¹æˆåŠŸæ¬¡æ•°
                    let success_count = rate_limit_tracker.get_success_count(node_id).await;
                    
                    // è·å–ä»»åŠ¡æˆåŠŸ
                    let timestamp = get_timestamp_efficient();
                    
                    // æ›´æ–°çŠ¶æ€æ˜¾ç¤ºæˆåŠŸæ¬¡æ•°
                    update_status(format!("[{}] è·å–ä»»åŠ¡ ({}/5) (æˆåŠŸ: {}æ¬¡)", timestamp, attempt + 1, success_count));
                    
                    // æ£€æŸ¥æ˜¯å¦æœ‰è¯¥ä»»åŠ¡çš„ç¼“å­˜è¯æ˜
                    if let Some((cached_proof_bytes, cached_proof_hash, attempts)) = orchestrator.get_cached_proof(&task.task_id) {
                        // æœ‰ç¼“å­˜çš„è¯æ˜ï¼Œç›´æ¥å°è¯•æäº¤
                        update_status(format!("[{}] ä½¿ç”¨ç¼“å­˜è¯æ˜é‡è¯•æäº¤ (å°è¯•æ¬¡æ•°: {})", timestamp, attempts + 1));
                        
                        // é’ˆå¯¹ç¼“å­˜çš„è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥è¿›è¡Œæ›´å¤šæ¬¡æ•°çš„é‡è¯•ï¼Œç‰¹åˆ«æ˜¯429é”™è¯¯
                        let mut retry_count = 0;
                        let mut rate_limited = false;
                        
                        // å¯¹äºç¼“å­˜çš„è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥æ›´ç§¯æåœ°é‡è¯•
                        while retry_count < MAX_429_RETRIES {
                            match orchestrator.submit_proof(&task.task_id, &cached_proof_hash, cached_proof_bytes.clone(), signing_key.clone()).await {
                                Ok(_) => {
                                    // æˆåŠŸæäº¤è¯æ˜
                                    proof_count += 1;
                                    _consecutive_failures = 0;
                                    // ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€æ ‡è®°å¯èƒ½æœªä½¿ç”¨çš„å˜é‡
                                    let _success = true; // è®¾ç½®æˆåŠŸçŠ¶æ€
                                    consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                    
                                    // é‡ç½®429è®¡æ•°
                                    rate_limit_tracker.reset_429_count(node_id).await;
                                    
                                    // è·å–æˆåŠŸè®¡æ•°ï¼ˆä¸å¢åŠ è®¡æ•°ï¼Œé¿å…é‡å¤è®¡æ•°ï¼‰
                                    let success_count = rate_limit_tracker.get_success_count(node_id).await;
                                    
                                    let msg = format!("[{}] âœ… ç¼“å­˜è¯æ˜æäº¤æˆåŠŸ! è¯æ˜ #{} å®Œæˆ (æˆåŠŸ: {}æ¬¡)", timestamp, proof_count, success_count);
                                    update_status(msg.clone());
                                    
                                    // å‘é€æˆåŠŸäº‹ä»¶
                                    let event_sender_clone = event_sender.clone();
                                    let task_id_clone = task.task_id.clone();
                                    tokio::spawn(async move {
                                        let _ = event_sender_clone
                                            .send(Event::proof_submitter(
                                                format!("Proof submitted successfully for task {}", task_id_clone),
                                                crate::events::EventType::ProofSubmitted,
                                            ))
                                            .await;
                                    });
                                    
                                    // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ï¼ŒæˆåŠŸæäº¤åè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                    if rotation_data.is_some() {
                                        println!("ğŸ”„ èŠ‚ç‚¹-{}: è¯æ˜æäº¤æˆåŠŸï¼Œè§¦å‘è½®è½¬", node_id);
                                        let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¯æ˜å·²è¢«æ¥å—", &node_tx).await;
                                        if should_rotate {
                                            if let Some(msg) = status_msg {
                                                update_status(msg);
                                            }
                                            return; // ç»“æŸå½“å‰èŠ‚ç‚¹çš„å¤„ç†
                                        } else {
                                            println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                        }
                                    } else {
                                        println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åŠŸèƒ½æœªå¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                    }
                                    
                                    break;
                                }
                                Err(e) => {
                                    let error_str = e.to_string();
                                    if error_str.contains("RATE_LIMITED") || error_str.contains("429") {
                                        // é€Ÿç‡é™åˆ¶é”™è¯¯ - ä½¿ç”¨éšæœºç­‰å¾…æ—¶é—´
                                        rate_limited = true;
                                        let wait_time = 30 + rand::random::<u64>() % 31; // 30-60ç§’éšæœº
                                        
                                        // å¢åŠ èŠ‚ç‚¹çš„429è®¡æ•°
                                        let _count = rate_limit_tracker.increment_429_count(node_id).await;
                                        consecutive_429s += 1; // å¢åŠ è¿ç»­429è®¡æ•°
                                        
                                        update_status(format!("[{}] ğŸš« 429é™åˆ¶ - ç­‰å¾…{}såé‡è¯•", 
                                            timestamp, wait_time));
                                        
                                        // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ä¸”è¿ç»­429é”™è¯¯è¾¾åˆ°é˜ˆå€¼ï¼Œè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                        if consecutive_429s >= MAX_CONSECUTIVE_429S_BEFORE_ROTATION && rotation_data.is_some() {
                                            println!("\nâš ï¸ èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯è¾¾åˆ°{}æ¬¡ï¼Œè§¦å‘è½®è½¬ (é˜ˆå€¼: {})\n", 
                                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION);
                                            
                                            println!("ğŸ”„ èŠ‚ç‚¹-{}: 429é”™è¯¯ï¼Œè§¦å‘è½®è½¬", node_id);
                                            let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¿ç»­429é”™è¯¯", &node_tx).await;
                                            if should_rotate {
                                                if let Some(msg) = status_msg {
                                                    update_status(format!("{}\nğŸ”„ èŠ‚ç‚¹å·²è½®è½¬ï¼Œå½“å‰èŠ‚ç‚¹å¤„ç†ç»“æŸ", msg));
                                                }
                                                // å‘é€ä¸€ä¸ªæ˜¾å¼çš„åœæ­¢æ¶ˆæ¯ï¼Œç¡®ä¿èŠ‚ç‚¹çœŸæ­£åœæ­¢
                                                let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
                                                println!("ğŸ›‘ èŠ‚ç‚¹-{}: è½®è½¬åæ˜¾å¼åœæ­¢", node_id);
                                                
                                                // è®¾ç½®åœæ­¢æ ‡å¿—
                                                should_stop.store(true, std::sync::atomic::Ordering::SeqCst);
                                                
                                                // å¼ºåˆ¶é€€å‡ºå½“å‰èŠ‚ç‚¹çš„å¤„ç†å¾ªç¯
                                                return;
                                            } else {
                                                println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                            }
                                        } else {
                                            println!("èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯: {}æ¬¡ (è½®è½¬é˜ˆå€¼: {}æ¬¡, è½®è½¬åŠŸèƒ½: {})", 
                                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION, rotation_data.is_some());
                                        }
                                        
                                        tokio::time::sleep(Duration::from_secs(wait_time)).await;
                                        retry_count += 1;
                                        continue;
                                    } else if error_str.contains("409") || error_str.contains("CONFLICT") || error_str.contains("å·²æäº¤") {
                                        // è¯æ˜å·²ç»è¢«æäº¤ï¼Œè§†ä¸ºæˆåŠŸ
                                        proof_count += 1;
                                        _consecutive_failures = 0;
                                        // ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€æ ‡è®°å¯èƒ½æœªä½¿ç”¨çš„å˜é‡
                                        let _success = true; // è®¾ç½®æˆåŠŸçŠ¶æ€
                                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                        
                                        // é‡ç½®429è®¡æ•°
                                        rate_limit_tracker.reset_429_count(node_id).await;
                                        
                                        // è·å–æˆåŠŸè®¡æ•°ï¼ˆä¸å¢åŠ è®¡æ•°ï¼Œå› ä¸º409è¡¨ç¤ºå·²ç»è¢«è®¡æ•°è¿‡äº†ï¼‰
                                        let success_count = rate_limit_tracker.get_success_count(node_id).await;
                                        
                                        let msg = format!("[{}] âœ… è¯æ˜å·²è¢«æ¥å— (409) (æˆåŠŸ: {}æ¬¡)", timestamp, success_count);
                                        update_status(msg.clone());
                                        
                                        // å‘é€æˆåŠŸäº‹ä»¶
                                        let event_sender_clone = event_sender.clone();
                                        let task_id_clone = task.task_id.clone();
                                        tokio::spawn(async move {
                                            let _ = event_sender_clone
                                                .send(Event::proof_submitter(
                                                    format!("Proof already accepted for task {}", task_id_clone),
                                                    crate::events::EventType::ProofSubmitted,
                                                ))
                                                .await;
                                        });
                                        
                                        // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ï¼ŒæˆåŠŸæäº¤åè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                        if rotation_data.is_some() {
                                            println!("ğŸ”„ èŠ‚ç‚¹-{}: è¯æ˜æäº¤æˆåŠŸï¼Œè§¦å‘è½®è½¬", node_id);
                                            let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¯æ˜å·²è¢«æ¥å—", &node_tx).await;
                                            if should_rotate {
                                                if let Some(msg) = status_msg {
                                                    update_status(msg);
                                                }
                                                return; // ç»“æŸå½“å‰èŠ‚ç‚¹çš„å¤„ç†
                                            } else {
                                                println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                            }
                                        } else {
                                            println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åŠŸèƒ½æœªå¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                        }
                                        
                                        break;
                                    } else {
                                        // é‡ç½®429è®¡æ•°ï¼ˆé429é”™è¯¯ï¼‰
                                        rate_limit_tracker.reset_429_count(node_id).await;
                                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                        
                                        update_status(format!("[{}] âŒ ç¼“å­˜è¯æ˜æäº¤å¤±è´¥: {}", timestamp, error_str));
                                        
                                        // æ£€æŸ¥æ˜¯å¦ä¸º404é”™è¯¯ï¼ˆä»»åŠ¡æœªæ‰¾åˆ°ï¼‰ï¼Œå¦‚æœæ˜¯åˆ™ä¸å†é‡è¯•
                                        if error_str.contains("404") || error_str.contains("NotFoundError") || error_str.contains("Task not found") {
                                            update_status(format!("[{}] ğŸ” ä»»åŠ¡å·²ä¸å­˜åœ¨ (404)ï¼Œåœæ­¢é‡è¯•å¹¶è·å–æ–°ä»»åŠ¡", timestamp));
                                            retry_count = MAX_429_RETRIES; // è®¾ç½®ä¸ºæœ€å¤§å€¼ä»¥è·³å‡ºå¾ªç¯
                                            break; // ç«‹å³é€€å‡ºé‡è¯•å¾ªç¯
                                        }
                                        
                                        // å¦‚æœä¸æ˜¯429é”™è¯¯ï¼Œæˆ‘ä»¬ä¸éœ€è¦é‚£ä¹ˆå¤šé‡è¯•
                                        if retry_count >= 2 {
                                            update_status(format!("[{}] æ”¾å¼ƒç¼“å­˜è¯æ˜ï¼Œå°è¯•é‡æ–°ç”Ÿæˆ...", timestamp));
                                            break;
                                        }
                                        tokio::time::sleep(Duration::from_secs(2)).await;
                                        retry_count += 1;
                                    }
                                }
                            }
                        }
                        
                        // å¦‚æœæˆåŠŸæäº¤æˆ–è¾¾åˆ°429é‡è¯•ä¸Šé™ä½†ä»æ˜¯é€Ÿç‡é™åˆ¶ï¼Œåˆ™ç»§ç»­ä¸‹ä¸€ä¸ªå¾ªç¯
                        if _success || (retry_count >= MAX_429_RETRIES && rate_limited) {
                            if !_success && rate_limited {
                                                                        update_status(format!("[{}] âš ï¸ 429é™åˆ¶ - ç­‰å¾…60såé‡è¯•", timestamp));
                                tokio::time::sleep(Duration::from_secs(60)).await; // é•¿æ—¶é—´ç­‰å¾…
                            }
                            break;
                        }
                    }
                    
                    // æ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜æäº¤å¤±è´¥ï¼Œé‡æ–°ç”Ÿæˆè¯æ˜
                    update_status(format!("[{}] æ­£åœ¨ç”Ÿæˆè¯æ˜...", timestamp));
                    
                    match crate::prover::authenticated_proving(&task, &environment, client_id.clone()).await {
                        Ok(proof) => {
                            // è¯æ˜ç”ŸæˆæˆåŠŸï¼Œå¼€å§‹æäº¤
                            update_status(format!("[{}] æ­£åœ¨æäº¤è¯æ˜...", timestamp));
                            
                            // è®¡ç®—å“ˆå¸Œ
                    let mut hasher = sha3::Sha3_256::new();
                            // å°†Proofè½¬æ¢ä¸ºVec<u8>
                            let proof_bytes = postcard::to_allocvec(&proof)
                                .unwrap_or_else(|_| Vec::new());
                            hasher.update(&proof_bytes);
                    let hash = hasher.finalize();
                    let proof_hash = format!("{:x}", hash);
                            
                            // æäº¤è¯æ˜ - å…‹éš†ç­¾åå¯†é’¥ä»¥é¿å…æ‰€æœ‰æƒé—®é¢˜
                            let mut retry_count = 0;
                            let mut rate_limited = false;
                            
                            while retry_count < MAX_SUBMISSION_RETRIES {
                                match orchestrator.submit_proof(&task.task_id, &proof_hash, proof_bytes.clone(), signing_key.clone()).await {
                                Ok(_) => {
                                    // æˆåŠŸæäº¤è¯æ˜
                                    proof_count += 1;
                                    _consecutive_failures = 0;
                                    // ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€æ ‡è®°å¯èƒ½æœªä½¿ç”¨çš„å˜é‡
                                    let _success = true; // è®¾ç½®æˆåŠŸçŠ¶æ€
                                    consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                    
                                    // é‡ç½®429è®¡æ•°
                                    rate_limit_tracker.reset_429_count(node_id).await;
                                    
                                    // è·å–æˆåŠŸè®¡æ•°ï¼ˆä¸å¢åŠ è®¡æ•°ï¼Œé¿å…é‡å¤è®¡æ•°ï¼‰
                                    let success_count = rate_limit_tracker.get_success_count(node_id).await;
                                    
                                    let msg = format!("[{}] âœ… è¯æ˜ #{} å®Œæˆ (æˆåŠŸ: {}æ¬¡)", timestamp, proof_count, success_count);
                                    update_status(msg.clone());
                                    
                                    // å‘é€æˆåŠŸäº‹ä»¶
                                    let event_sender_clone = event_sender.clone();
                                    tokio::spawn(async move {
                                        let _ = event_sender_clone
                                            .send(Event::proof_submitter(
                                                format!("Proof submitted successfully for task {}", task.task_id),
                                                crate::events::EventType::ProofSubmitted,
                                            ))
                                            .await;
                                    });
                                    
                                    #[cfg(debug_assertions)]
                                    {
                                        println!("\nğŸ” èŠ‚ç‚¹-{}: è¯æ˜æäº¤æˆåŠŸï¼Œå‡†å¤‡è½®è½¬...", node_id);
                                        println!("ğŸ” èŠ‚ç‚¹-{}: rotation_dataæ˜¯å¦å­˜åœ¨: {}\n", node_id, rotation_data.is_some());
                                    }
                                    
                                    // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ï¼ŒæˆåŠŸæäº¤åè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                    if rotation_data.is_some() {
                                        println!("ğŸ”„ èŠ‚ç‚¹-{}: è¯æ˜æäº¤æˆåŠŸï¼Œè§¦å‘è½®è½¬", node_id);
                                        let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "æˆåŠŸæäº¤è¯æ˜", &node_tx).await;
                                        if should_rotate {
                                            if let Some(msg) = status_msg {
                                                update_status(msg);
                                            }
                                            // å‘é€ä¸€ä¸ªæ˜¾å¼çš„åœæ­¢æ¶ˆæ¯ï¼Œç¡®ä¿èŠ‚ç‚¹çœŸæ­£åœæ­¢
                                            let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
                                            println!("ğŸ›‘ èŠ‚ç‚¹-{}: è½®è½¬åæ˜¾å¼åœæ­¢", node_id);
                                            
                                            // è®¾ç½®åœæ­¢æ ‡å¿—
                                            should_stop.store(true, std::sync::atomic::Ordering::SeqCst);
                                            
                                            // å¼ºåˆ¶é€€å‡ºå½“å‰èŠ‚ç‚¹çš„å¤„ç†å¾ªç¯
                                            return;
                                        } else {
                                            println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                        }
                                    } else {
                                        println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åŠŸèƒ½æœªå¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                    }
                                    
                                    break;
                                }
                                Err(e) => {
                                    let error_str = e.to_string();
                                    if error_str.contains("RATE_LIMITED") || error_str.contains("429") {
                                        // é€Ÿç‡é™åˆ¶é”™è¯¯
                                        rate_limited = true;
                                        
                                        // å¢åŠ èŠ‚ç‚¹çš„429è®¡æ•°
                                        let _count = rate_limit_tracker.increment_429_count(node_id).await;
                                        consecutive_429s += 1; // å¢åŠ è¿ç»­429è®¡æ•°
                                        
                                        // ç¼“å­˜è¯æ˜ä»¥ä¾¿åç»­é‡è¯•
                                        orchestrator.cache_proof(&task.task_id, &proof_hash, &proof_bytes);
                                        
                                        let wait_time = 30 + rand::random::<u64>() % 31; // 30-60ç§’éšæœº
                                        update_status(format!("[{}] ğŸš« 429é™åˆ¶ - ç­‰å¾…{}såé‡è¯•", 
                                            timestamp, wait_time));
                                        
                                        // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ä¸”è¿ç»­429é”™è¯¯è¾¾åˆ°é˜ˆå€¼ï¼Œè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                        if consecutive_429s >= MAX_CONSECUTIVE_429S_BEFORE_ROTATION && rotation_data.is_some() {
                                            println!("\nâš ï¸ èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯è¾¾åˆ°{}æ¬¡ï¼Œè§¦å‘è½®è½¬ (é˜ˆå€¼: {})\n", 
                                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION);
                                            
                                            println!("ğŸ”„ èŠ‚ç‚¹-{}: 429é”™è¯¯ï¼Œè§¦å‘è½®è½¬", node_id);
                                            let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¿ç»­429é”™è¯¯", &node_tx).await;
                                            if should_rotate {
                                                if let Some(msg) = status_msg {
                                                    update_status(format!("{}\nğŸ”„ èŠ‚ç‚¹å·²è½®è½¬ï¼Œå½“å‰èŠ‚ç‚¹å¤„ç†ç»“æŸ", msg));
                                                }
                                                // å‘é€ä¸€ä¸ªæ˜¾å¼çš„åœæ­¢æ¶ˆæ¯ï¼Œç¡®ä¿èŠ‚ç‚¹çœŸæ­£åœæ­¢
                                                let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
                                                println!("ğŸ›‘ èŠ‚ç‚¹-{}: è½®è½¬åæ˜¾å¼åœæ­¢", node_id);
                                                
                                                // è®¾ç½®åœæ­¢æ ‡å¿—
                                                should_stop.store(true, std::sync::atomic::Ordering::SeqCst);
                                                
                                                // å¼ºåˆ¶é€€å‡ºå½“å‰èŠ‚ç‚¹çš„å¤„ç†å¾ªç¯
                                                return;
                                            } else {
                                                println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                            }
                                        } else {
                                            println!("èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯: {}æ¬¡ (è½®è½¬é˜ˆå€¼: {}æ¬¡, è½®è½¬åŠŸèƒ½: {})", 
                                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION, rotation_data.is_some());
                                        }
                                        
                                        tokio::time::sleep(Duration::from_secs(wait_time)).await;
                                    } else if error_str.contains("409") || error_str.contains("CONFLICT") || error_str.contains("å·²æäº¤") {
                                        // è¯æ˜å·²ç»è¢«æäº¤ï¼Œè§†ä¸ºæˆåŠŸ
                                        proof_count += 1;
                                        _consecutive_failures = 0;
                                        // ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€æ ‡è®°å¯èƒ½æœªä½¿ç”¨çš„å˜é‡
                                        let _success = true; // è®¾ç½®æˆåŠŸçŠ¶æ€
                                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                        
                                        // é‡ç½®429è®¡æ•°
                                        rate_limit_tracker.reset_429_count(node_id).await;
                                        
                                        // è·å–æˆåŠŸè®¡æ•°ï¼ˆä¸å¢åŠ è®¡æ•°ï¼Œå› ä¸º409è¡¨ç¤ºå·²ç»è¢«è®¡æ•°è¿‡äº†ï¼‰
                                        let success_count = rate_limit_tracker.get_success_count(node_id).await;
                                        
                                        let msg = format!("[{}] âœ… è¯æ˜å·²è¢«æ¥å— (409) (æˆåŠŸ: {}æ¬¡)", timestamp, success_count);
                                        update_status(msg.clone());
                                        
                                        // å‘é€æˆåŠŸäº‹ä»¶
                                        let event_sender_clone = event_sender.clone();
                                        let task_id_clone = task.task_id.clone();
                                        tokio::spawn(async move {
                                            let _ = event_sender_clone
                                                .send(Event::proof_submitter(
                                                    format!("Proof already accepted for task {}", task_id_clone),
                                                    crate::events::EventType::ProofSubmitted,
                                                ))
                                                .await;
                                        });
                                        
                                        // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ï¼ŒæˆåŠŸæäº¤åè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                                        if rotation_data.is_some() {
                                            println!("ğŸ”„ èŠ‚ç‚¹-{}: è¯æ˜æäº¤æˆåŠŸï¼Œè§¦å‘è½®è½¬", node_id);
                                            let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¯æ˜å·²è¢«æ¥å—", &node_tx).await;
                                            if should_rotate {
                                                if let Some(msg) = status_msg {
                                                    update_status(msg);
                                                }
                                                return; // ç»“æŸå½“å‰èŠ‚ç‚¹çš„å¤„ç†
                                            } else {
                                                println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                            }
                                        } else {
                                            println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬åŠŸèƒ½æœªå¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                                        }
                                        
                                        break;
                                    } else {
                                        // å…¶ä»–é”™è¯¯
                                        _consecutive_failures += 1;
                                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                                        
                                        // é‡ç½®429è®¡æ•°
                                        rate_limit_tracker.reset_429_count(node_id).await;
                                        
                                        update_status(format!("[{}] âŒ è¯æ˜æäº¤å¤±è´¥: {} (é‡è¯• {}/{})", 
                                            timestamp, error_str, retry_count + 1, MAX_SUBMISSION_RETRIES));
                                        
                                        // æ£€æŸ¥æ˜¯å¦ä¸º404é”™è¯¯ï¼ˆä»»åŠ¡æœªæ‰¾åˆ°ï¼‰ï¼Œå¦‚æœæ˜¯åˆ™ä¸å†é‡è¯•
                                        if error_str.contains("404") || error_str.contains("NotFoundError") || error_str.contains("Task not found") {
                                            update_status(format!("[{}] ğŸ” ä»»åŠ¡å·²ä¸å­˜åœ¨ (404)ï¼Œåœæ­¢é‡è¯•å¹¶è·å–æ–°ä»»åŠ¡", timestamp));
                                            retry_count = MAX_429_RETRIES; // è®¾ç½®ä¸ºæœ€å¤§å€¼ä»¥è·³å‡ºå¾ªç¯
                                            break; // ç«‹å³é€€å‡ºé‡è¯•å¾ªç¯
                                        }
                                        
                                        // ç¼“å­˜è¯æ˜ä»¥ä¾¿åç»­é‡è¯•
                                        if retry_count == 0 {
                                            orchestrator.cache_proof(&task.task_id, &proof_hash, &proof_bytes);
                                        }
                                        
                                        tokio::time::sleep(Duration::from_secs(2)).await;
                                    }
                                    retry_count += 1;
                                }
                            }
                            }
                            
                            if _success || retry_count >= MAX_SUBMISSION_RETRIES {
                                if !_success {
                                    // å¦‚æœæ˜¯ç”±äºé€Ÿç‡é™åˆ¶è€Œå¤±è´¥ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
                                    if rate_limited {
                                        update_status(format!("[{}] âš ï¸ 429é™åˆ¶ - ç­‰å¾…60såé‡è¯•", timestamp));
                                        tokio::time::sleep(Duration::from_secs(60)).await;
                                    } else {
                                        update_status(format!("[{}] âš ï¸ æäº¤å¤±è´¥ - ç­‰å¾…5såé‡è¯•", timestamp));
                                        tokio::time::sleep(Duration::from_secs(5)).await;
                                    }
                                }
                                break;
                            }
                        }
                        Err(e) => {
                            // è¯æ˜ç”Ÿæˆå¤±è´¥
                            _consecutive_failures += 1;
                            consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                            
                            // é‡ç½®429è®¡æ•°
                            rate_limit_tracker.reset_429_count(node_id).await;
                            
                            update_status(format!("[{}] âŒ è¯æ˜ç”Ÿæˆå¤±è´¥: {}", timestamp, e));
                            tokio::time::sleep(Duration::from_secs(2)).await;
                        }
                    }
                    
                    // æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½é€€å‡ºå°è¯•å¾ªç¯
                    break;
                }
                Err(e) => {
                    let error_str = e.to_string();
                    if error_str.contains("RATE_LIMITED") || error_str.contains("429") {
                        // é€Ÿç‡é™åˆ¶é”™è¯¯
                        let _count = rate_limit_tracker.increment_429_count(node_id).await;
                        consecutive_429s += 1; // å¢åŠ è¿ç»­429è®¡æ•°
                        
                        let wait_time = 30 + rand::random::<u64>() % 31; // 30-60ç§’éšæœº
                                                                update_status(format!("[{}] ğŸš« 429é™åˆ¶ - ç­‰å¾…{}såé‡è¯•", 
                                            timestamp, wait_time));
                        
                        // å¦‚æœå¯ç”¨äº†è½®è½¬åŠŸèƒ½ä¸”è¿ç»­429é”™è¯¯è¾¾åˆ°é˜ˆå€¼ï¼Œè½®è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
                        if consecutive_429s >= MAX_CONSECUTIVE_429S_BEFORE_ROTATION && rotation_data.is_some() {
                            println!("\nâš ï¸ èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯è¾¾åˆ°{}æ¬¡ï¼Œè§¦å‘è½®è½¬ (é˜ˆå€¼: {})\n", 
                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION);
                            
                            println!("ğŸ”„ èŠ‚ç‚¹-{}: 429é”™è¯¯ï¼Œè§¦å‘è½®è½¬", node_id);
                            let (should_rotate, status_msg) = rotate_to_next_node(node_id, &rotation_data, "è¿ç»­429é”™è¯¯", &node_tx).await;
                            if should_rotate {
                                if let Some(msg) = status_msg {
                                    update_status(format!("{}\nğŸ”„ èŠ‚ç‚¹å·²è½®è½¬ï¼Œå½“å‰èŠ‚ç‚¹å¤„ç†ç»“æŸ", msg));
                                }
                                // å‘é€ä¸€ä¸ªæ˜¾å¼çš„åœæ­¢æ¶ˆæ¯ï¼Œç¡®ä¿èŠ‚ç‚¹çœŸæ­£åœæ­¢
                                let _ = node_tx.send(NodeManagerCommand::NodeStopped(node_id)).await;
                                println!("ğŸ›‘ èŠ‚ç‚¹-{}: è½®è½¬åæ˜¾å¼åœæ­¢", node_id);
                                
                                // è®¾ç½®åœæ­¢æ ‡å¿—
                                should_stop.store(true, std::sync::atomic::Ordering::SeqCst);
                                
                                // å¼ºåˆ¶é€€å‡ºå½“å‰èŠ‚ç‚¹çš„å¤„ç†å¾ªç¯
                                return;
                            } else {
                                println!("âš ï¸ èŠ‚ç‚¹-{}: è½®è½¬å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰èŠ‚ç‚¹", node_id);
                            }
                        } else {
                            println!("èŠ‚ç‚¹-{}: è¿ç»­429é”™è¯¯: {}æ¬¡ (è½®è½¬é˜ˆå€¼: {}æ¬¡, è½®è½¬åŠŸèƒ½: {})", 
                                node_id, consecutive_429s, MAX_CONSECUTIVE_429S_BEFORE_ROTATION, rotation_data.is_some());
                        }
                        
                        tokio::time::sleep(Duration::from_secs(wait_time)).await;
                    } else if error_str.contains("404") || error_str.contains("NOT_FOUND") {
                        // 404é”™è¯¯ - æ— å¯ç”¨ä»»åŠ¡
                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                        
                        // é‡ç½®429è®¡æ•°
                        rate_limit_tracker.reset_429_count(node_id).await;
                        
                        update_status(format!("[{}] ğŸ” æ— å¯ç”¨ä»»åŠ¡ (404) (å°è¯• {}/{})", 
                            timestamp, attempt, MAX_TASK_RETRIES));
                        tokio::time::sleep(Duration::from_secs(5)).await;
                    } else {
                        // å…¶ä»–é”™è¯¯
                        _consecutive_failures += 1;
                        consecutive_429s = 0; // é‡ç½®è¿ç»­429è®¡æ•°
                        
                        // é‡ç½®429è®¡æ•°
                        rate_limit_tracker.reset_429_count(node_id).await;
                        
                        update_status(format!("[{}] âŒ è·å–ä»»åŠ¡å¤±è´¥: {} (å°è¯• {}/{})", 
                            timestamp, error_str, attempt, MAX_TASK_RETRIES));
                        tokio::time::sleep(Duration::from_secs(2)).await;
                    }
                    attempt += 1;
                }
            }
        }
        
        // å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åå†è¯•
        if !_success && attempt > MAX_TASK_RETRIES {
            update_status(format!("[{}] âš ï¸ è·å–ä»»åŠ¡å¤±è´¥ï¼Œç­‰å¾…åé‡è¯•...", timestamp));
            tokio::time::sleep(Duration::from_secs(5)).await;
        }
        
        // å¦‚æœå¯ç”¨äº†è¯æ˜é—´éš”ï¼Œç­‰å¾…æŒ‡å®šæ—¶é—´
        if proof_interval > 0 {
            let wait_time = proof_interval + (rand::random::<u64>() % 2); // æ·»åŠ 0-1ç§’çš„éšæœºå˜åŒ–
            update_status(format!("[{}] â±ï¸ ç­‰å¾… {}s åç»§ç»­...", timestamp, wait_time));
            tokio::time::sleep(Duration::from_secs(wait_time)).await;
        }
    }
}

// æ¸…ç†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œç¡®ä¿åªæœ‰çœŸæ­£æ´»åŠ¨çš„èŠ‚ç‚¹è¢«åŒ…å«
async fn cleanup_active_nodes(
    active_nodes: &Arc<Mutex<Vec<u64>>>, 
    active_threads: &Arc<Mutex<HashMap<u64, bool>>>,
    max_concurrent: usize
) {
    // è·å–å½“å‰çœŸæ­£æ´»è·ƒçš„èŠ‚ç‚¹
    let active_node_ids: Vec<u64>;
    {
        let threads_guard = active_threads.lock();
        active_node_ids = threads_guard.iter()
            .filter(|pair| *pair.1)
            .map(|(&id, _)| id)
            .collect();
    }
    
    // åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ï¼Œä»¥ä¾¿åé¢å¯ä»¥å†æ¬¡ä½¿ç”¨
    let active_node_ids_for_empty_check = active_node_ids.clone();
    
    // å¦‚æœæ²¡æœ‰æ´»è·ƒèŠ‚ç‚¹ï¼Œè¯´æ˜å¯èƒ½å‡ºç°äº†é—®é¢˜ï¼Œæ‰“å°è­¦å‘Š
    if active_node_ids_for_empty_check.is_empty() {
        // æ£€æŸ¥å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆæ˜¯å¦ä¹Ÿä¸ºç©º
        let global_active_count = get_global_active_node_count();
        if global_active_count == 0 {
            println!("âš ï¸ è­¦å‘Š: æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•æ´»è·ƒèŠ‚ç‚¹ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜");
        } else {
            println!("âš ï¸ è­¦å‘Š: æœ¬åœ°æ´»è·ƒèŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œä½†å…¨å±€æœ‰ {} ä¸ªæ´»è·ƒèŠ‚ç‚¹ï¼Œå°è¯•æ¢å¤...", global_active_count);
            // ä»å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆæ¢å¤
            let global_active_nodes = {
                let nodes = GLOBAL_ACTIVE_NODES.lock();
                nodes.clone()
            };
            
            // æ›´æ–°æ´»åŠ¨çº¿ç¨‹çŠ¶æ€
            let mut threads_guard = active_threads.lock();
            for node_id in global_active_nodes {
                threads_guard.insert(node_id, true);
            }
        }
    }
    
    // å¦‚æœæ´»è·ƒèŠ‚ç‚¹æ•°é‡è¶…è¿‡æœ€å¤§å¹¶å‘æ•°ï¼Œå¼ºåˆ¶é™åˆ¶
    let active_node_ids_limited = if active_node_ids.len() > max_concurrent {
        if VERBOSE_OUTPUT {
            println!("âš ï¸ èŠ‚ç‚¹æ¸…ç†: æ´»è·ƒèŠ‚ç‚¹æ•°é‡ ({}) è¶…è¿‡æœ€å¤§å¹¶å‘æ•° ({}), è¿›è¡Œé™åˆ¶", 
                    active_node_ids.len(), max_concurrent);
        }
        
        // åªä¿ç•™å‰max_concurrentä¸ªèŠ‚ç‚¹
        active_node_ids.iter().take(max_concurrent).cloned().collect::<Vec<u64>>()
    } else {
        active_node_ids
    };
    
    // è·å–å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆçš„å½“å‰çŠ¶æ€
    let global_active_count = get_global_active_node_count();
    
    // å¦‚æœå…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡ä¸å®é™…æ´»è·ƒèŠ‚ç‚¹æ•°é‡ä¸ä¸€è‡´ï¼Œæ‰“å°è­¦å‘Š
    if global_active_count != active_node_ids_limited.len() {
        println!("âš ï¸ èŠ‚ç‚¹æ¸…ç†: å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡ ({}) ä¸å®é™…æ´»è·ƒèŠ‚ç‚¹æ•°é‡ ({}) ä¸ä¸€è‡´", 
                global_active_count, active_node_ids_limited.len());
    }
    
    // æ›´æ–°æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰çœŸæ­£æ´»è·ƒçš„èŠ‚ç‚¹
    {
        let mut nodes_guard = active_nodes.lock();
        
        // æ£€æŸ¥å½“å‰æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨çŠ¶æ€
        if nodes_guard.len() < active_node_ids_limited.len() {
            println!("âš ï¸ èŠ‚ç‚¹æ¸…ç†: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ ({}) å°äºå®é™…æ´»è·ƒèŠ‚ç‚¹æ•°é‡ ({}), éœ€è¦æ·»åŠ èŠ‚ç‚¹", 
                    nodes_guard.len(), active_node_ids_limited.len());
        } else if nodes_guard.len() > max_concurrent {
            println!("âš ï¸ èŠ‚ç‚¹æ¸…ç†: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ ({}) è¶…è¿‡æœ€å¤§å¹¶å‘æ•° ({}), éœ€è¦å‡å°‘èŠ‚ç‚¹", 
                    nodes_guard.len(), max_concurrent);
        }
        
        // åªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µæ‰æ‰§è¡Œå®Œå…¨é‡å»º:
        // 1. æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©º
        // 2. æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨å¤§å°ä¸å®é™…æ´»è·ƒèŠ‚ç‚¹æ•°é‡å·®å¼‚è¶…è¿‡2
        // 3. æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨è¶…è¿‡æœ€å¤§å¹¶å‘æ•°
        let should_rebuild = nodes_guard.is_empty() || 
                            (nodes_guard.len() as i64 - active_node_ids_limited.len() as i64).abs() > 2 ||
                            nodes_guard.len() > max_concurrent;
        
        if should_rebuild {
            // å¼ºåˆ¶æ¸…ç©ºæ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œä»¥ç¡®ä¿ä¸‹é¢çš„æ“ä½œä»é›¶å¼€å§‹ï¼Œé¿å…ç´¯ç§¯
            nodes_guard.clear();
            if VERBOSE_OUTPUT {
                println!("ğŸ§¹ èŠ‚ç‚¹æ¸…ç†: å·²æ¸…ç©ºæ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ï¼Œé‡æ–°å¡«å……");
            }
            
            // å¡«å……æœ€å¤šmax_concurrentä¸ªæ´»è·ƒèŠ‚ç‚¹
            let nodes_to_add = active_node_ids_limited.iter()
                .take(max_concurrent)
                .cloned()
                .collect::<Vec<u64>>();
            
            if !nodes_to_add.is_empty() {
                nodes_guard.extend(nodes_to_add);
                println!("âœ… èŠ‚ç‚¹æ¸…ç†: å·²æ·»åŠ {}ä¸ªæ´»è·ƒèŠ‚ç‚¹åˆ°æ´»åŠ¨åˆ—è¡¨ (å®Œå…¨é‡å»º)", nodes_guard.len());
            }
        } else {
            // å¢é‡æ›´æ–°: ç§»é™¤ä¸å†æ´»è·ƒçš„èŠ‚ç‚¹
            nodes_guard.retain(|node_id| {
                let active_threads_guard = active_threads.lock();
                active_threads_guard.get(node_id).copied().unwrap_or(false)
            });
            
            // å¦‚æœèŠ‚ç‚¹æ•°é‡å°äºæœ€å¤§å¹¶å‘æ•°ï¼Œå°è¯•æ·»åŠ æ›´å¤šèŠ‚ç‚¹
            if nodes_guard.len() < max_concurrent {
                // æ‰¾å‡ºå½“å‰ä¸åœ¨åˆ—è¡¨ä¸­ä½†æ˜¯æ´»è·ƒçš„èŠ‚ç‚¹
                let missing_nodes: Vec<u64> = active_node_ids_limited.iter()
                    .filter(|id| !nodes_guard.contains(id))
                    .cloned()
                    .collect();
                
                // æ·»åŠ ç¼ºå¤±çš„èŠ‚ç‚¹ï¼Œç›´åˆ°è¾¾åˆ°æœ€å¤§å¹¶å‘æ•°
                for node_id in missing_nodes {
                    if nodes_guard.len() >= max_concurrent {
                        break;
                    }
                    nodes_guard.push(node_id);
                }
                
                if VERBOSE_OUTPUT {
                    println!("âœ… èŠ‚ç‚¹æ¸…ç†: å¢é‡æ›´æ–° - å½“å‰æ´»åŠ¨èŠ‚ç‚¹æ•°é‡: {}", nodes_guard.len());
                }
            }
        }
        
        // å†æ¬¡ç¡®ä¿æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸è¶…è¿‡æœ€å¤§å¹¶å‘æ•°
        if nodes_guard.len() > max_concurrent {
            if VERBOSE_OUTPUT {
                println!("âš ï¸ èŠ‚ç‚¹æ¸…ç†: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä»ç„¶è¶…å‡ºé™åˆ¶ ({} > {}), å¼ºåˆ¶æˆªæ–­", 
                        nodes_guard.len(), max_concurrent);
            }
            nodes_guard.truncate(max_concurrent);
            if VERBOSE_OUTPUT {
                println!("âœ… èŠ‚ç‚¹æ¸…ç†: å·²å¼ºåˆ¶æˆªæ–­æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨è‡³ {} ä¸ªèŠ‚ç‚¹", nodes_guard.len());
            }
        }
        
        // è·å–å½“å‰çœŸæ­£æ´»è·ƒçš„èŠ‚ç‚¹
        let current_active_node_ids: Vec<u64> = {
            let threads_guard = active_threads.lock();
            threads_guard.iter()
                .filter(|pair| *pair.1)
                .map(|(&id, _)| id)
                .collect()
        };
        
                        // å¦‚æœæ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºä½†æœ‰æ´»è·ƒèŠ‚ç‚¹ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¥é‡é—®é¢˜
                if nodes_guard.is_empty() && !current_active_node_ids.is_empty() {
                    println!("ğŸš¨ ä¸¥é‡é”™è¯¯: æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ºç©ºï¼Œä½†æœ‰ {} ä¸ªæ´»è·ƒèŠ‚ç‚¹", current_active_node_ids.len());
                    // ç´§æ€¥æ·»åŠ æ´»è·ƒèŠ‚ç‚¹
                    nodes_guard.extend(current_active_node_ids.iter().take(max_concurrent).cloned());
                    println!("ğŸš¨ ç´§æ€¥ä¿®å¤: å·²æ·»åŠ  {} ä¸ªæ´»è·ƒèŠ‚ç‚¹åˆ°æ´»åŠ¨åˆ—è¡¨", nodes_guard.len());
                }
                
                // æ£€æŸ¥å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆæ˜¯å¦ä¸ºç©ºæˆ–æ•°é‡ä¸è¶³ï¼Œå¦‚æœæ˜¯ä½†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸ä¸ºç©ºï¼Œåˆ™åŒæ­¥
                let global_active_count = get_global_active_node_count();
                if (global_active_count == 0 || global_active_count < max_concurrent / 2) && !nodes_guard.is_empty() {
                    println!("ğŸš¨ ç´§æ€¥æƒ…å†µ: å…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡ä¸è¶³ ({}), ä½†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨æœ‰ {} ä¸ªèŠ‚ç‚¹", 
                            global_active_count, nodes_guard.len());
                    
                    // ç´§æ€¥åŒæ­¥å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
                    let mut global_nodes = GLOBAL_ACTIVE_NODES.lock();
                    
                    // å¦‚æœå…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆä¸ºç©ºï¼Œåˆ™å®Œå…¨é‡å»º
                    if global_nodes.is_empty() {
                        for &node_id in nodes_guard.iter().take(max_concurrent) {
                            global_nodes.insert(node_id);
                            
                            // åŒæ—¶ç¡®ä¿èŠ‚ç‚¹åœ¨active_threadsä¸­æ ‡è®°ä¸ºæ´»è·ƒ
                            let mut threads_guard = active_threads.lock();
                            threads_guard.insert(node_id, true);
                        }
                        println!("ğŸš¨ ç´§æ€¥ä¿®å¤: å·²æ·»åŠ  {} ä¸ªèŠ‚ç‚¹åˆ°ç©ºçš„å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ", global_nodes.len());
                    } 
                    // å¦‚æœå…¨å±€æ´»è·ƒèŠ‚ç‚¹æ•°é‡ä¸è¶³ï¼Œåˆ™è¡¥å……
                    else if global_nodes.len() < max_concurrent / 2 {
                        // æ‰¾å‡ºä¸åœ¨å…¨å±€é›†åˆä¸­çš„èŠ‚ç‚¹
                        let nodes_to_add: Vec<u64> = nodes_guard.iter()
                            .filter(|&&node_id| !global_nodes.contains(&node_id))
                            .take(max_concurrent - global_nodes.len())
                            .copied()
                            .collect();
                        
                        // æ·»åŠ è¿™äº›èŠ‚ç‚¹
                        for &node_id in &nodes_to_add {
                            global_nodes.insert(node_id);
                            
                            // åŒæ—¶ç¡®ä¿èŠ‚ç‚¹åœ¨active_threadsä¸­æ ‡è®°ä¸ºæ´»è·ƒ
                            let mut threads_guard = active_threads.lock();
                            threads_guard.insert(node_id, true);
                        }
                        
                        println!("ğŸš¨ ç´§æ€¥ä¿®å¤: å·²æ·»åŠ  {} ä¸ªèŠ‚ç‚¹åˆ°å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆï¼Œç°æœ‰ {} ä¸ª", 
                                nodes_to_add.len(), global_nodes.len());
                    }
                }
    }
    
    // æ›´æ–°active_threadsï¼Œç¡®ä¿ä¸æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸€è‡´
    {
        let nodes_guard = active_nodes.lock();
        let mut threads_guard = active_threads.lock();
        
        // é¦–å…ˆå°†æ‰€æœ‰èŠ‚ç‚¹æ ‡è®°ä¸ºéæ´»è·ƒ
        for (_, is_active) in threads_guard.iter_mut() {
            *is_active = false;
        }
        
        // ç„¶åå°†æ´»åŠ¨èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„èŠ‚ç‚¹æ ‡è®°ä¸ºæ´»è·ƒ
        for &node_id in nodes_guard.iter() {
            threads_guard.insert(node_id, true);
        }
    }
    
    // åŒæ­¥å…¨å±€æ´»è·ƒèŠ‚ç‚¹é›†åˆ
    sync_global_active_nodes(active_threads, max_concurrent);
}

#[cfg(test)]
mod tests {
    use crate::orchestrator::MockOrchestrator;
    use crate::prover_runtime::{Event, MAX_COMPLETED_TASKS, online::fetch_prover_tasks};
    use crate::task::Task;
    use crate::task_cache::TaskCache;
    use std::time::Duration;
    use tokio::sync::{broadcast, mpsc};

    /// Creates a mock orchestrator client that simulates fetching tasks.
    fn get_mock_orchestrator_client() -> MockOrchestrator {
        let mut i = 0;
        let mut mock = MockOrchestrator::new();
        mock.expect_get_proof_task().returning_st(move |_, _| {
            // Simulate a task with dummy data
            let task = Task::new(i.to_string(), format!("Task {}", i), vec![1, 2, 3]);
            i += 1;
            Ok(task)
        });
        mock
    }

    #[tokio::test]
    // Should fetch and enqueue tasks from the orchestrator.
    async fn test_task_fetching() {
        let orchestrator_client = Box::new(get_mock_orchestrator_client());
        let signer_key = ed25519_dalek::SigningKey::generate(&mut rand::rngs::OsRng);
        let verifying_key = signer_key.verifying_key();
        let node_id = 1234;

        let task_queue_size = 10;
        let (task_sender, mut task_receiver) = mpsc::channel::<Task>(task_queue_size);

        // Run task_master in a tokio task to stay in the same thread context
        let (shutdown_sender, _) = broadcast::channel(1); // Only one shutdown signal needed
        let (event_sender, _event_receiver) = mpsc::channel::<Event>(100);
        let shutdown_receiver = shutdown_sender.subscribe();
        let successful_tasks = TaskCache::new(MAX_COMPLETED_TASKS);

        let task_master_handle = tokio::spawn(async move {
            fetch_prover_tasks(
                node_id,
                verifying_key,
                orchestrator_client,
                task_sender,
                event_sender,
                shutdown_receiver,
                successful_tasks,
            )
            .await;
        });

        // Receive tasks
        let mut received = 0;
        for _i in 0..task_queue_size {
            match tokio::time::timeout(Duration::from_secs(2), task_receiver.recv()).await {
                Ok(Some(task)) => {
                    println!("Received task {}: {:?}", received, task);
                    received += 1;
                }
                Ok(None) => {
                    eprintln!("Channel closed unexpectedly");
                    break;
                }
                Err(_) => {
                    eprintln!("Timed out waiting for task {}", received);
                    break;
                }
            }
        }

        task_master_handle.abort();
    }
}
